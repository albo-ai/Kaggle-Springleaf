{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import cross_validation\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import hinge_loss\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "from scipy.sparse import hstack,csr_matrix\n",
    "import cPickle as pickle\n",
    "import random\n",
    "# xgBoost AUC: 0.76833777818980442\n",
    "# RF AUC: 0.75744520850500441"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X=np.load('./pickledata/nxtrain_standard_original0.npy')\n",
    "X1= np.load('./pickledata/nxtrain_standard_derived0.npy')\n",
    "X2=pickle.load(open(\"./pickledata/time_series_derived_standard_train2.dat\",\"rb\"))\n",
    "X3=pickle.load(open(\"./pickledata/time_series_original_standard_train2.dat\",\"rb\"))\n",
    "X4=pickle.load(open(\"./pickledata/cat_numeric_th60_standard_train2.dat\",\"rb\"))\n",
    "X5=pickle.load(open(\"./pickledata/cat_le_train2.dat\",\"rb\"))#label encoded categorical data 15 in total\n",
    "y=pickle.load(open(\"./pickledata/ytrain2.dat\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X=np.hstack((X,X1,X2,X3,X4,X5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_roc(fpr, tpr):\n",
    "    \"\"\"Plot ROC curve and display it.\"\"\"\n",
    "    plt.clf()\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.savefig('plots/ROC_curve.png')\n",
    "\n",
    "    \n",
    "def learning_curve(model, X_train, y_train, X_cv, y_cv,n=20):\n",
    "    \"\"\"Plot train and cv loss for increasing train sample sizes.\"\"\"\n",
    "    chunk = int(len(y)/n)\n",
    "    n_samples = []\n",
    "    train_losses = []\n",
    "    cv_losses = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        train_subset = X_train[:(i + 1)*chunk]\n",
    "        MD = model.fit(X_train[:(i + 1)*chunk], y_train[:(i + 1)*chunk])\n",
    "        \n",
    "        preds_train = model.predict_proba(X_train[:(i + 1)*chunk])\n",
    "        preds_cv = model.predict_proba(X_cv)\n",
    "        \n",
    "        n_samples.append((i + 1)*chunk)\n",
    "        cv_losses.append(hinge_loss(y_cv, preds_cv, labels=0))\n",
    "        train_losses.append(hinge_loss(y_train[:(i + 1)*chunk], preds_train, labels=0))\n",
    "\n",
    "    plt.gca()\n",
    "    plt.plot(n_samples, train_losses, 'r--', n_samples, cv_losses, 'b--')\n",
    "    plt.gca()\n",
    "    plt.plot(n_samples, train_losses,'ro--',label='train_loss')\n",
    "    plt.plot(n_samples, cv_losses, 'bd--',label='cv_loss')\n",
    "    plt.legend(loc='best',fontsize='medium')\n",
    "    plt.xlabel('sample size')\n",
    "    plt.ylabel('hinge loss')\n",
    "    plt.ylim([min(train_losses) - .01, max(cv_losses) + .01])\n",
    "\n",
    "    plt.savefig('plots/learning_curve.png')\n",
    "    plt.show()\n",
    "    \n",
    "def cv_loop(X, y, model, N, SEED=40, diagnostics=False, randomsplit=False):   # N random splits into train and test sets with the test of 1/N fraction\n",
    "    # Return the ((mean and std of the cv AUC score), and fscore)\n",
    "    AUC = np.zeros(N) \n",
    "    if N ==1:\n",
    "        skf = cross_validation.StratifiedKFold(y, n_folds=2) # K-fold cv splitting\n",
    "        if len(X.shape)==1:#to be compatible with forward selection\n",
    "            fscore_total = 0\n",
    "        else:\n",
    "            fscore_total = np.zeros((X.shape[1],2)) #feature num * 2\n",
    "    else:# N >=2 folds\n",
    "        skf = cross_validation.StratifiedKFold(y, n_folds=N) # K-fold cv splitting\n",
    "        if len(X.shape)==1:#to be compatible with forward selection\n",
    "            fscore_total = 0\n",
    "        else:\n",
    "            fscore_total = np.zeros((X.shape[1],N)) #feature num * N-fold cv\n",
    "\n",
    "    i=0\n",
    "    for train, cv in skf:\n",
    "        if randomsplit: # random split of the row index\n",
    "            train, cv = cross_validation.train_test_split(range(len(y)), test_size=1.0/float(N), random_state = i*SEED)\n",
    "            \n",
    "        if len(X.shape)==1:\n",
    "            MODEL = model.fit(X[train], y[train])\n",
    "            preds_cv = model.predict_proba(X[cv])\n",
    "        else:\n",
    "            MODEL = model.fit(X[train,:], y[train])\n",
    "            preds_cv = model.predict_proba(X[cv,:])\n",
    "            fscore_cv = model.fscore #raw fscore dictionary eg ['f100':1]\n",
    "            fscore_list =[[int(ftemp[1:]), vtemp] for ftemp, vtemp in fscore_cv.iteritems()]\n",
    "            fscore_list.sort(key=lambda fv:fv[0])#sort based on the feature names(indices)\n",
    "            #some features have no fscore, assumed to be 0\n",
    "            fscore_features = [fscore_list_temp[0] for fscore_list_temp in fscore_list]\n",
    "            fscore_values =   [fscore_list_temp[1] for fscore_list_temp in fscore_list]\n",
    "            fscore_total[fscore_features,i] = fscore_values#fill in for the i-th fold\n",
    "        \n",
    "        fpr, tpr, _ = metrics.roc_curve(y[cv], preds_cv)\n",
    "        roc_auc = metrics.auc(fpr, tpr)\n",
    "    \n",
    "        AUC[i] = roc_auc\n",
    "\n",
    "        # plot learning curve and roc curve for diagonistics purpose\n",
    "        if diagnostics and i == 0:  # only plot for first fold\n",
    "            print(\"plotting ROC curve\")\n",
    "            plot_roc(fpr, tpr)\n",
    "            print(\"plotting learning curve\")\n",
    "            if len(X.shape)==1:\n",
    "                learning_curve(model, X[train], y[train], X[cv,:], y[cv])\n",
    "            else:\n",
    "                learning_curve(model, X[train,:], y[train], X[cv,:], y[cv])\n",
    "        i+=1\n",
    "        if N==1: #for N=1, since minimum N should be 2 in StratifiedKFold\n",
    "            #duplicate the fscore\n",
    "            fscore_total[:,1]=fscore_total[:,0]\n",
    "            mean_auc = AUC\n",
    "            std_auc = 0\n",
    "            break\n",
    "    if N>1:\n",
    "        mean_auc = AUC.mean()\n",
    "        std_auc = AUC.std()\n",
    "        \n",
    "    if len(X.shape)==1:\n",
    "        fscore = 0\n",
    "    else:\n",
    "        fscore = fscore_total.mean(axis=1)\n",
    "    \n",
    "    return ((mean_auc, std_auc), fscore) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def feature_selection_backward(model, params, Xtrain, ytrain, diagonistics=False, SEED=42, num_rows=10000, drop_features_percent=0.1, feature_num_thresh=10, n_cv_rounds = 2, auc_prec=10000,auc_prec2=10000):\n",
    "    \"Backward feature selection using feature importance in xgboost\"\n",
    "\n",
    "    print \"Performing backward feature selection...\"\n",
    "    score_hist = []\n",
    "    total_features = np.asarray(range(Xtrain.shape[1])) #all the columns, fixed column numbers for all the features\n",
    "    good_features = total_features #column of the features in the original matrix\n",
    "    use_features = total_features[good_features]#the column being used\n",
    "    userows_hist=[]#check random number generator\n",
    "    \n",
    "    MODEL = model.set_params(random_state=SEED)\n",
    "    MODEL.set_params(params=params)\n",
    "    \n",
    "    bestAUC=0\n",
    "    \n",
    "    while len(good_features)>=feature_num_thresh: #stop when there are feature_num_thresh features left \n",
    "        scores = []    \n",
    "        if num_rows < Xtrain.shape[0]:\n",
    "            #random sampling for stochastic feature selection\n",
    "            userows = sorted(random.sample(range(Xtrain.shape[0]), num_rows))\n",
    "        else:\n",
    "            #use all the rows\n",
    "            userows = range(Xtrain.shape[0])     \n",
    "        if userows == userows_hist and num_rows < Xtrain.shape[0]:\n",
    "            userows = sorted(random.sample(range(Xtrain.shape[0]), num_rows))\n",
    "            print('Two randomly chosen lists appeared to be the same')\n",
    "        userows_hist = userows\n",
    "        \n",
    "        #get the fscore of all the features using a cv_loop\n",
    "        score, fscore_temp = cv_loop(Xtrain[userows, :][:,use_features], ytrain[userows], MODEL, N=n_cv_rounds)\n",
    "        \n",
    "        if round(score[0] * auc_prec) >= round(bestAUC * auc_prec):\n",
    "            bestAUC = score[0]\n",
    "            score_hist.append(bestAUC) \n",
    "            print('\\t\\t\\t\\t %d features left. Current AUC: %f' % ( len(good_features), bestAUC))\n",
    "            #save results\n",
    "            str1=time.strftime(\"%b%d%Y_%H%M%S\", time.localtime())\n",
    "            with open(('XGBoost_backward_selection_' + str(len(use_features)) +'Features '+str1 + '_AUC_' + '0p'+ str(int(bestAUC*1e5))  +'.p'), 'wb') as f:\n",
    "                pickle.dump(use_features, f, protocol =2)\n",
    "            with open(('fscores_' + str(len(use_features)) +'Features '+str1 + '_AUC_' + '0p'+ str(int(bestAUC*1e5))  +'.p'), 'wb') as f2:\n",
    "                pickle.dump(fscore_temp, f2, protocol =2)\n",
    "            \n",
    "            #drop redundant features\n",
    "            #fscore_temp is an array corresponding to the fscores of the good features being used.\n",
    "            fscore_sorted_index = np.argsort(fscore_temp)[::-1]         \n",
    "            good_feature_rows = int(len(fscore_sorted_index) * (1- drop_features_percent))#how many rows to keep\n",
    "            \n",
    "            good_features = fscore_sorted_index[0:good_feature_rows]#index in the current use_feature\n",
    "            other_features  = fscore_sorted_index[good_feature_rows:]#index in the current use_feature\n",
    "            #update hist_features first, since use_features itself will be updated shortly\n",
    "            hist_features = use_features[other_features]#use_features contain the indices in the total_features\n",
    "            #update use_features, to be used in next loop\n",
    "            use_features  = use_features[good_features] #use_features contain the indices in the total_features\n",
    "        else:\n",
    "            #score is not better than the last bestAUC\n",
    "            #recover the dropped features one by one till the AUC is >= bestAUC\n",
    "            #break if all features dropped in the last step are recovered\n",
    "            bestAUC_recover = 0\n",
    "            score_hist.append(score[0]) #show the trend\n",
    "            with open(('XGBoost_backward_selection_' + str(len(use_features)) +'Features '+str1 + '_AUC_' + '0p'+ str(int(bestAUC*1e5))  +'.p'), 'wb') as f3:\n",
    "                pickle.dump(use_features, f3, protocol =2)\n",
    "            with open(('fscores_' + str(len(use_features)) +'Features '+str1 + '_AUC_' + '0p'+ str(int(bestAUC*1e5))  +'.p'), 'wb') as f4:\n",
    "                pickle.dump(fscore_temp, f4, protocol =2)\n",
    "                \n",
    "            print('AUC found in this step (%f) is worse than %f in the last step. Recovering features from %d features' %(score[0], bestAUC, len(hist_features)))\n",
    "            for f in range(len(hist_features)):                           \n",
    "                use_features = np.append(use_features, hist_features[f])\n",
    "                score, fscore_temp = cv_loop(Xtrain[userows, :][:,use_features], ytrain[userows], MODEL, N=n_cv_rounds)\n",
    "                score_hist.append(score[0])\n",
    "                if round(score[0] * auc_prec2) >= round(bestAUC * auc_prec2):\n",
    "                    if round(score[0] * auc_prec2) >= round(bestAUC_recover * auc_prec2):\n",
    "                        bestAUC_recover = score[0] #found it, but let's keep improving.\n",
    "                    else:\n",
    "                        break;#found it. And we cannot do better. \n",
    "                \n",
    "            bestAUC = score[0] #or all the hist_features are included \n",
    "            #save results\n",
    "            str1=time.strftime(\"%b%d%Y_%H%M%S\", time.localtime())\n",
    "            with open(('XGBoost_backward_selection_' + str(len(use_features)) +'Features '+str1 + '_AUC_' + '0p'+ str(int(bestAUC*1e5))  +'.p'), 'wb') as f5:\n",
    "                pickle.dump(use_features, f5, protocol =2)\n",
    "            \n",
    "            print('All good hist_features recovered, no more selection is necessary.')\n",
    "            print('Final best AUC is %f' % bestAUC)\n",
    "            break #the while loop           \n",
    "            \n",
    "    if diagonistics:\n",
    "        plt.clf()\n",
    "        plt.plot(range(len(score_hist)),score_hist,'ro--')\n",
    "        plt.xlabel('number of selected features')\n",
    "        plt.ylabel('AUC score')\n",
    "        plt.title('Feature-selection curve')\n",
    "        plt.savefig('plots/featsel_curve.png')\n",
    "    \n",
    "    print('Feature selection done: %d features selected'%len(use_features))\n",
    "    \n",
    "    return use_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class XGBoostClassifier():\n",
    "    def __init__(self, num_boost_round=10, **params):\n",
    "        self.clf = None\n",
    "        self.num_boost_round = num_boost_round\n",
    "        self.params = params\n",
    "        self.params.update({'objective': 'binary:logistic'})\n",
    " \n",
    "    def fit(self, X, y, num_boost_round=None):\n",
    "        num_boost_round = num_boost_round or self.num_boost_round\n",
    "        dtrain = xgb.DMatrix(X, label=y)\n",
    "        self.clf = xgb.train(params=self.params, dtrain=dtrain, num_boost_round=num_boost_round)\n",
    "        self.fscore = self.clf.get_fscore()\n",
    "        \n",
    "    def predict(self, X):\n",
    "        num2label = {i: label for label, i in self.label2num.items()}\n",
    "        Y = self.predict_proba(X)\n",
    "        y = np.argmax(Y, axis=1)\n",
    "        return np.array([num2label[i] for i in y])\n",
    " \n",
    "    def predict_proba(self, X):\n",
    "        dtest = xgb.DMatrix(X)\n",
    "        return self.clf.predict(dtest)\n",
    " \n",
    "    def score(self, X, y):\n",
    "        Y = self.predict_proba(X)\n",
    "        return 1 / self.logloss(y, Y)\n",
    " \n",
    "    def get_params(self, deep=True):\n",
    "        return self.params\n",
    " \n",
    "    def set_params(self, **params):\n",
    "        if 'num_boost_round' in params:\n",
    "            self.num_boost_round = params.pop('num_boost_round')\n",
    "        if 'objective' in params:\n",
    "            del params['objective']\n",
    "        self.params.update(params)\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def logloss(self,y_true, Y_pred):\n",
    "        label2num = dict((name, i) for i, name in enumerate(sorted(set(y_true))))\n",
    "        return -1 * sum(math.log(y[label2num[label]]) if y[label2num[label]] > 0 else -np.inf \\\n",
    "                        for y, label in zip(Y_pred, y_true)) / len(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgbclassifier = XGBoostClassifier(num_boost_round=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {'max_depth':14, \n",
    "             'eta':0.01, \n",
    "             'objective':'binary:logistic', \n",
    "             'subsample':0.6,\n",
    "             'colsample_bytree':0.6,\n",
    "             'eval_metric': 'auc'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing backward feature selection...\n",
      "\t\t\t\t 1762 features left. Current AUC: 0.772257\n",
      "\t\t\t\t 1409 features left. Current AUC: 0.772358\n",
      "\t\t\t\t 1127 features left. Current AUC: 0.772297\n",
      "\t\t\t\t 901 features left. Current AUC: 0.772328\n",
      "\t\t\t\t 720 features left. Current AUC: 0.772457\n",
      "\t\t\t\t 576 features left. Current AUC: 0.772327\n",
      "AUC found in this step (0.771375) is worse than 0.772327 in the last step. Recovering features from 116 features\n",
      "All good hist_features recovered, no more selection is necessary.\n",
      "Final best AUC is 0.772285\n",
      "Feature selection done: 487 features selected\n",
      "Time elapsed = 159.063416668\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAAEZCAYAAABb3GilAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl8VOXZ//HPFxAVVFC0LoAiEa17xRatC8YFgitq3a2t\nrW2tVqn1pxUFKj5WpdW2Cn1stdU+VivuVUtUwCVEa90QFRBRIsjiAiqgBRUC1++P+wSGYSaZSc7J\nLLner9e8OHPWe2bCXHPu5bplZjjnnHNxalfoAjjnnCs/Hlycc87FzoOLc8652Hlwcc45FzsPLs45\n52LnwcU551zsPLg418okVUqal8B5D5b0Vtznda45PLi4gpA0R9JySZ9Hj88kbRPDOQ+Lq4zFTtJq\nSb0bnpvZs2b29UKWybkGHlxcoRhwjJltGj02M7MPYzinmnuwpPYtvH4hNPv1tjZJHQpdBtd6PLi4\noiKpi6TbJL0vab6kqyW1i7ZVSHpa0seSFkm6S1KXaNudwPbAv6I7oUsyVT+l3t1IGinpAUl3SloK\nfL+x62cp7x8kfSRpqaQ3JO0erd9Q0g2S3pP0oaQ/Sdooyzm2k/SgpIWS3pV0Ycq2dpKukDQrurt7\nWVIPSbXRLq9Hr/fk9NcraVdJNZIWS5om6diUbf8n6X8ljYvO+0LqXVCGMh4k6fnoXHMlfS9aXyPp\nnJT9zpb0bMrz1ZLOl/Q28LakmyVdn3buRyT9oqn3wpUWDy6ukDL96v4/YAVQAewDDAR+lLL9GmBb\nYFegJzASwMzOAuay9m7ohizXTM93dBxwv5l1Ae7O4fprCy9VAQcDfaLjTwY+iTaPAnYC9o7+7Q78\nKsM52gH/AqYA2wGHAxdJGhjt8v+A04AjzWwz4BxguZn1j7bvFb3e+9POu0F03ieArYALgX9I2jll\nt1MJ79/mwCzCe5vpde4APAbcBGwJfAN4PdpsrP+ephsM9CN8ZmOj6zace3NgADA2h/fClRAPLq5Q\nBDwc/RJeLOkhSVsDRwK/MLMvzGwRcCPhyxUzqzOzp8xspZl9DPwBOKSF5XjezB6Nlrs0dv0MVgCb\nArtKamdmM83sQ0kCfgxcbGZLzOy/wHVZzvMtYEsz+7WZ1ZvZbOCvKfv+CBhmZu9E78EbZvZpDq9r\nf6CzmY2KzvsMMA44PWWfh8zsFTNbBfyDEDQyOQOYaGb3mtkqM/vUzF7Psm8m10Xvw1fAc4BJOjja\ndhLhM/iQpt8LV0K8DtQVigGDzezphhWS+gEbAB+E72cg/ACaG23fmvDr+SDCl3o7IJcv2sbMT1ne\noYnrTydUvQEMMrNnJP0R+F9gB0kPAZcAGwOdgMkp5xGZf8ztAGwnaXHKuvZAQ7VXD6CuGa9rOyC9\nR9p70XoI7/9HKdu+ADbJcq4ewLvNKEODNeUwM5N0DyHIPUsIXH+PNjf1XrgS4sHFFZN5wFdANzNb\nnWH7tcAqYA8zWyLpeGBMyvb06pllhC95YE2D/VZp+6Qe0+j1zWz3DOvGAGMkbQXcB1wKXEn4st7N\nzD7I9ELTrjnbzHZuZPtOwJtNnCfd+0BPSbK1qc93AJrTVXkeoVork2VA55TnmXr8pX8uY4EJkn4T\nnXdwtH4ujb8XroR4tZgrGtEX8QTg95I2jRqzKyQ1tC9sQvgy+0xSd8IXeaqPCG0lDd4GNpJ0VNQG\nMRzYsAXXX4ekb0raLzr3cuBLYFX0Zf4X4MYo6CCpe5a2g5eAzyX9UtLGktpL2kPSN6PtfwWulrST\ngr0kbZHl9aZ6MSrTLyVtIKkSOAa4p6H42d6HDP4BHBF1GuggqZukvaNtrwEnRmXfidAm1Cgzew34\nOHptT5jZZ9Gmpt4LV0I8uLhi8z2gI+GX+qfA/az9NXwV0BdYSmj4fZB1fxVfBwyP2nAuNrOlwPmE\nL7H5wH9Zt6ooU2N0Y9dPtxlwa7TfHMIXZkNPqMsIjeQvKPREmwik/iI3gKi94xhCe8e7wKLonJtF\n+/2ecEc0IXrdfwEaep2NBO6IXu9Jqa/HzFYAxxLakBYBfwTOMrO3G3ntGRvmzWwecBShc8EnhAb3\nvaLNfyC0PX0E/A24K+082Rr77wYOi/5tuM7qJt4LV0KU5GRhkgYRGkTbA381s9+kbb8EODN62oHQ\nm2RLYGvW/sIC6A2MMLPRkq4m9PAxwh/62dEfP5IuB35IqDoZYmYTknptzjnnskssuET12zOBI4AF\nwMvA6WY2I8v+xwAXmdkRaevbRcf3M7N5kjY1s8+jbRcCe5vZjyTtRvgV9C1Ct88ngZ2z1N0755xL\nUJLVYv2AWWY2x8xWEu5EBjey/xmEhr50RwB1DXcnDYElsgmhKoLo3GOjbqpzCFUS2RohnXPOJSjJ\n3mLdWbd+ez6wX6YdJXUCqgj14+lOI6VeNtr/GuAsQo+chgCyHfBC2vW6N6fgzjnnWibJO5d86tuO\nBZ4zsyWpKyV1jLatM/rYzIaZ2faEBsQbYyqDc865mCR557KAkJ6jQU/WHbCW6jQyV4kdCUyORkpn\ncjchLUWm6/WI1q1Dkgcc55xrBjPLuQt7kncurwB9JPWK7kBOBR5N30kh8WB/4JEM5zidtKAjqU/K\n08GEbpFE5z5NUkdJOwJ9CP3m12NmJfu48sorC16Gtlr+Ui67l7/wj1Ivf74Su3Mxs3pJFwDjCV2R\nbzOzGZLOjbbfEu16PDDezL5IPV5SZ0Jj/o/TTn2dpF0I3Y3rgPOi870p6T7C+IR64HxrzjvinHOu\nxRJN/2JmjwOPp627Je35HcAdGY5dRhjzkr7+pEaudy0hRYhzzrkC8hH6JaaysrLQRWiRUi5/KZcd\nvPyFVurlz1eiI/SL0bp5/JxzzuVCElYkDfrOOefaKA8uzjnnYufBxTnnXOw8uDjnnIudBxfnnHOx\n8+DinHMudh5cnHPOxc6Di3POudh5cHHOORc7Dy7OOedi58HFOedc7Dy4OOeci50HF+ecc7Hz4OKc\ncy52Hlycc87FzoOLc8652Hlwcc45F7sOhS6Ac8653NRWVzNh9Gg6fPUV9RtuyMAhQ+h/9NGFLlZG\nHlycc64E1FZXM/7nP+eauro164ZFy8UYYLxazDnnSsCE0aPXCSwA19TVMXHMmAKVqHEeXJxzrgR0\n+OqrjOvbf/llK5ckNx5cnHOuBNRvuGHG9as22qiVS5IbDy7OOVcCBg4ZwrCKinXWXVFRwYALLyxQ\niRonMyt0GVqVJGtrr9k5Vx5qq6uZOGYM7efPZ9X77zPgzjtbrTFfEmamnPdva1+0HlyccyXr/fdh\nq61g9Wro3h1efRW2375VLp1vcPFqMeecKxWnnw5PPQUbbggnnQR3313oEmWVaHCRNEjSW5LekXRZ\nhu2XSJoSPaZKqpfUVdIuKeunSFoqaUh0zPWSZkh6XdJDkrpE63tJ+iLlmJuTfG3OOdeqvvwSJk+G\nAw8Mz7/7XbjnnsKWqRGJVYtJag/MBI4AFgAvA6eb2Yws+x8DXGRmR6Stbxcd38/M5kkaADxlZqsl\njQIws6GSegH/MrM9myiXV4s550rPpElw6aXw0kvh+erV8MknoZqsFRRTtVg/YJaZzTGzlcA9wOBG\n9j8DGJth/RFAnZnNAzCziWa2Otr2ItAjxjI751xxqq2FQw5Z+7xdu1YLLM2RZHDpDsxLeT4/Wrce\nSZ2AKuDBDJtPA7JVLP4QeCzl+Y5RlViNpIPyL7JzzhWpSZPWDS5FLsncYvnUPR0LPGdmS1JXSuoY\nbcvUXjMMWGFmDYHnfaCnmS2W1Bd4WNLuZvZ584rvnHNFpGtXOKh0fjMnGVwWAD1Tnvck3L1kchqZ\nq8SOBCab2aLUlZLOBo4CDm9YZ2YrgBXR8quS6oA+wKvpJx05cuSa5crKSiorK5t6LYkppSynzrkC\neuCBVr1cTU0NNTU1zT4+yQb9DoQG/cMJdxUvkaFBP+rt9S7Qw8y+SNt2D/C4md2Rsm4Q8DvgEDP7\nOGX9lsBiM1slqTdQC+yR4W6oaBr0M2Y5raig6qabPMA453I3cSIccAB07pzYJYqmQd/M6oELgPHA\nm8C9ZjZD0rmSzk3Z9XhgfIbA0pnQmP9Q2qnHAJsAE9O6HB8CvC5pCnA/cG56YCk2pZbl1DlXpP7w\nB3jkkUKXYh2JzudiZo8Dj6etuyXt+R3AHaQxs2XAlhnW98lyrQfJ3CGgaJVallPnXJH67nfhrrvg\njDMKXZI1fIR+AZVallPnXJEaPBiefx4++qjQJVnDg0uhzJvHwDPPXD/Lafv2DOiT8ebMOdcWTZgA\nL7/c+D6dO8Nxx8G997ZOmXLgwaUQ5s2DQw+lf309VTfdxIiqKkYecggjqqoY9Kc/0f/hh+G22wpd\nSudcMRg9GubMaXq/734X7rwz8eLkyrMip0m8a3AUWDj/fLj44sz7vPMOHHYYXHUV/PCH8V3bOVda\nVq2Cbt1g5kzYeuvG962vh7FjQ5BRzp26cpZvb7FEG/RLTcauwdFyLAEml8AC0KdPyHz605/CmWeG\nDKjOubbnjTdg222bDiwAHTrAWWclX6YcebVYikS7Bi9enFtgabDzzvD00x5YnGvLSizlSyq/c0kR\nd9fg9arYfvIT+ucSWHI5l4/kd678TZoEp5xS6FI0iweXFFm7Bn/+OZjlVY+ZtYpt993zDgqJV9c5\n54rTOefA/vsXuhTN4tViKQYOGbJ+1+CvfY0Bn34KBx8cAgzhy354VRUjKysZXlVFbXX12gNWr4ap\nU5lw442xVbH5SH7n2qhjjoEt1xtL3rQvv4SVK+MvTx78zuWzz2CzzYC1dwEjxoyh/ZdfsmqjjRh0\n4YX0P+oomDULpMx3EdOnw4AB9P/4Y/j3v6FbNzp07Zrxcs2pYvOR/M65fNQefDAT6uvp0KVLwarR\n225wqa+HoUNhypTQMyvS/+ijM38I0cDGjHcRCxYw4umn6X/DDXDrrbDtttRXVWW8bHNG3/tIfudc\nrmqrqxn/3ntcs2htMvlCVKO3yWqx4ZWV1H7jGzBtGtx3X17HZr2L2HFHOPnk0G2QLFVsFRUMuPDC\nvMsb57mcc+VtwujR6wQWKEw1epu8c/n1pEkM23xzuPZa+nfrltexud5FZK1ia8YvhzXn+vWvaT91\nKqsOOqjZ53LOlbdiqUZvk8EF4JrFixlx8830P+64vI4bOGQIw+rq1qkau6KigkEZ7iKyVrE1Q/+j\nj6b/t78NvXvD448nMgLXOVck7rgDPvwQLltvEt4mFUs1epsNLtC8SB7nHUneNt8cNt44dELo0iX5\n6znnCuOJJ2DAgGYdms8P4CS1zdxi0fKIqiqufuKJgpYnb3mOt3HOlRgz6NEDamshra01V7XV1UxM\n+QE8IIYfwPnmFmuzweWKigoG+XTCzrliM2tWSPkyf35R/ZD0xJU5GFFV5Q3izrni1JBPrIgCS3O0\nyeBSclVhzrmSlXdewP/8p2STVaZqk8HFOecaE1ei2GblBbzlloKnbomDB5dSYwYffADbbVfokjhX\nluJMFJstL+CIMWOyn6t9+/AocW1yhH5JW7UKdtwRsgyUcs61TJyJYrMOaFy+fJ3njSbDLVF+51Jq\nOnSAnj3DnNq77FLo0pQ8nyfHpcsnIGT82zELjfJ/+hP1H3+c8VyrXnoJKivhyCOp7dyZ8WlZ1Mth\nSg0PLqWoogLq6jy4tJDPk+MyyTrC/T//CfPTX3MNtdOmrf+388478K9/0b+2Nqw4/3wGfuc7DLvi\nivUHNI4aBRttBI8/zoTbb+eatAHdTVadlQAPLqWoogLefbfQpSh5zaoPj4HfLRW3rCPcR4yAZctg\n000z/+3Mns2Ihx+m/z33rOlK3B+gc+fsGT2OOYYO06aFAZNpSn1KDQ8upah373Dn4lqkEAn+/G6p\n+OWS4inr387Xvx6qu9LO19hnW58l51epT6nhwaUU7bZbGL3rWqS+Y8eM65P8T12ouyWXnyYDQozJ\nIYslF1jcPLiUoqOOCg/XIgP79GHYc89xzRdfrFmX9H/qYkmH7lomzoBQ0GS4CfLg4tqmpUvp/+CD\nMGoUIx57jPaTJrFq330ZdPnlif6nLpZ06K4RS5fCuHFw5plZd4k7IMQ5PUexSDRxpaRBwI1Ae+Cv\nZvabtO2XAA2fYAdgV2BLYGvgnpRdewMjzGy0pOuBY4AVQB3wAzNbGp3vcuCHwCpgiJlNyFAma2vJ\nOl0Gl10GixbB7beH56ecAoMHN/qFEofa6mrGf+97XPPpp2vWeRLVIjN+PIwaBc88U+iSFJWiyYos\nqT0wEzgCWAC8DJxuZjOy7H8McJGZHZG2vl10fD8zmydpAPCUma2WNArAzIZK2g24G/gW0B14EtjZ\nzFannc+DS1s3ezZ885swderaTAejRoVg87vfJX752gMOYOKyZbTffPPY0qG7GF11FXz5JVx3XaFL\nUlSKKStyP2CWmc0BkHQPMBjIGFyAM4CxGdYfAdSZ2TwAM5uYsu1F4DvR8mBgrJmtBOZImhWV4YUW\nvg5XboYPh4suWjeFTt++rfZl0n/+fPo/8wzssAM8+ywcemirXNfl6IUX4Kc/LXQpSl6S6V+6A/NS\nns+P1q1HUiegCngww+bTCHckmfwQeCxa3i66RpPXKwuLFnl35Oa65hr4f/9v3XX77ANTpsDq1ZmP\nicuHH4axEr17h2udeqqPWSomq1fDiy/CfvsVuiQlL8k7l3zqno4FnjOzJakrJXWMtq03kbSkYcAK\nM8sWeLKWYeTIkWuWKysrqUzrl14SqqvhySfhrrsKXZLS06vX+uu22grOOQeWL4dNNknu2gsWhLYd\nCTp2hNNOgzvvhCuvTO6aLnfvvBOmEN9mm0KXpOBqamqoqalp9vFJtrnsD4w0s0HR88uB1emN+tG2\nfwL3mtk9aesHA+c1nCNl/dnAj4HDzezLaN1QADMbFT1/ArjSzF5MO7Y82lyefTY0Sj//fKFL4lpi\n8uTQmWDWrJKfHKosvPcePPdc4h07SlG+bS5JVou9AvSR1Cu6AzkVeDR9J0ldgP7AIxnOcTpp7TBR\nD7RLgcENgSXyKHCapI6SdgT6AC/F8kqKkY/SLw99+4YcU//+d6FL4iC0g3lgiUViwcXM6oELgPHA\nm4Q7kxmSzpV0bsquxwPjzeyL1OMldSY05j+UduoxwCbARElTJN0cXe9N4L7oWo8D55fHLUoW224L\nn30G//1voUviWkKC738f7rij0CVxLlaJjnMpRmVTLQYhDcy998Keexa6JMXtgw9CA/4//lGcVU8f\nfBAakY8/vtAlcS6rYuqK7JJ29NE+aVgW62QefucdBh5wAP2LMbBAuAv1wOLKjN+5uLKTMfPwjjtS\nlUtyyPvvD/Xu/frFX7DnnguziHYv3x7yrnwVU4O+cwWRba6NnKapff31kFcqCUOHwsyZyZzbtdyI\nEeHzd7Hw4OLKTosyD/ftC6++GnOJgPp6eO012Hff+M/tWs4M/vpX6Nq10CUpGx5cXNlpUebhpILL\n9OnQs2cYoNeYZcvCF51rXXPnhn+3376w5SgjHlxc2Rk4ZAjDKirWWXdFRQUDcplrY4cdQieJDz6I\nt1AvvQTf+lbT++23X7jDca3rhRdg//2LszdhifLeYqXuqadCVYvfzq/Rork2pHD3MmVK6MUVl5df\nzq2TwIknwt//HnKdudbTEFxcbLy3WKk75BAYOdIz68aptjZUYe24Y3znvOUW6N8fdt218f1mzYID\nDwzTWG+wQXzXd4379rfDtAuHHFLokhStROZzkXQwsJOZ/U3SVsAmZja7BeUsmLILLj/8IRxwAPzo\nR4UuSYutMzZlww0ZOGRI25zn5MAD4fLL4ZhjCl2StmPGjPBjwmcEzSr2QZSSRgL7ArsAfwM6AncB\nBzazjC5OZZJjLOPYlGi5zQWYhnQwHlxaT1N3lC5vuTTon0CYiGsZgJktADZNslAuDxUVZTEfSMax\nKXV1uY1NSbdkSavMKJmYU06BTTf1XmOupOUSXL5KnSo4SijpikU53Lm89x4dZmSeoDSnsSnpJk0K\n86CXqq5d4fbbveeSK2m59Ba7X9ItQFdJPyHM/vjXZIvlctanT6ijL3KNtqdcfTX1Wb5Icxqbku7p\np+Gww1pQ2sLz9idX8sws6wMQsD0wELghegxo7Jhif4SX7FrTpHHj7IqKCrNQ0WMGdkVFhU0aN67R\nfS5P2ydne+xh9uKLLSv0s8+aXXppy85hZvbpp2ZDh+Z1SC7vl4vJqlVmq1cXuhQlIfruzP27ttGN\nIbhMy+eExf7w4NL6hg0cuM4XZcNjeFXVOvtNGjfOhldV2ZWHHGLDq6qa92X64YdmXbqYrVzZskJP\nm2bWp0/LzmFmNn68Wf/+eR2S6/uVq0njxtmwgQPtykMOsWEDB3qQSvXww2annFLoUpSEfINLo9Vi\nZmaSJkvqZ2blO6ujS1SHRYsyrk9vT+l/9NEtr/p55pkwVqFDC8cH77ILvP9+mJBts82af55cB0+m\naFFutDTeC68JL7wQ5kVysculQX9/4D+S3pU0NXq8kXTBXBlYtQp+/Wvqp03LvDmJMQX9+sGvftXy\n83ToAHvt1fJULLmmfUnRotxoaWLthVeOfGR+YnIJLlVABXAocAxwLHBckoVyZWDBAqishGeeYeCt\ntzY/11e+eveOL/NwS5NYmoXgkuedS4tyo6WJ8y6o7NTXwyuvJDN3j2u6t5iZzZH0DeBgwIBnzcwn\nPSgmCxeGHGOnn17okqzVqVMYr/Gzn9G/XTvYaqv8c3398pdw9tmFq7bo2zdUszXXggXhC2yHHfI6\nbJ3caBMmsOrwwxl00UXNqsaK8y6o7EyfDj16wOabF7okZanJ9C+Sfg78GHiI0MB/PPAXMxudfPHi\nV3bpXyAMojzsMJgzp9UvnWiX2Ysugi22iKeaqzmWLg0Zkr/2teYd//nnMHlyuINrrp13hkcfha9/\nvVmHZ2pzuaKigkE33eRtLg88ABMmwK23FrokJSH23GKSpgL7m9my6Hln4AUz27NFJS2QsgwuK1fC\nJpuEL7OOHVvtshkbiysqqIrri+vZZ+GCC9r27ICHHx5msBwwoNmnqK2uZuKYMbSfMoVVX/saA0aN\n8sDSwMwHq+Yo9txikdVZll0x2GCDcHs/Z074pdtKsjUWj8hlrvpcHHAAfPRRyBS8004tP18p6tkT\n5s1r0Sn6H300/R94ALbZBrp1Aw8sa3lgSUwuDfp/A16UNFLSVcALwO3JFsvlrXfvVs8xlnhjcfv2\ncMIJ8OCDTe/71lvlmS79F7+IZzqFCRNCw/X06S0/l3M5aDK4mNnvgR8Ai4FPgLPN7A9JF8zlqaKi\n1XOMtUpj8Xe+A4880vR+Tz8dAmy52Xvvls8rs2IFLFoUqtY8uLhW0mRwkbQ/8I6Z3RQ14tdJ2i/5\norm8nHhiq/eqirPLbFaVlfDEE03vl2Q+sfr6ZM7bWt5/P1SJVVTAsGGebdm1ilwa9F8D9mloBZfU\nHnjFzEpyHtaybNAvoNq//IWJQ4bQfr/9WLXRRgzIdTrhOK1eDVttBW+8Ad27x3vuFStg663hww8h\ny51aRsOHw557wqmnxlue5qithSuugOeeK3RJCm5N78ZFi6jv1o2Bzezi3RYl0qCf+m1sZquiAOMc\n/bt1o/+AAaG7bKG8/noILnEHFgi977bfHqZNy29w5lNPtaiHV6zmzg2voY3L2LtxdphQ1wNM/HJp\n0J8taYikDSR1jMa9lP7sVC4eG2xQ+BkTX3stdNlNSr4j9VesCHdRffsmV6Z8HH00XHttoUtRcJ4K\np3XlElx+SpjSeAEwn5Br7Ce5nFzSIElvSXpH0mUZtl8iaUr0mCqpXlJXSbukrJ8iaamkIdExJ0ua\nLmmVpL4p5+ol6YuUY27OpYyuhY49Fn6S059Dcn7wA0jyCyLf4DJtWmiE3zSmCVvPOw/efrv5x2++\nOfTqFU9ZSpinwmlduaR/+QjIu+I4qjr7I3AEITC9LOlRM1sz5aCZNcwRg6RjgIvMbAmwBNgnWt8u\nOv6f0WFTCVMv35LhsrNKtS3INWHFipBksH//zNvb5fI7qZn69oU778x9/2Ykq2zU7NlhrE8rjmEq\nR54Kp3Xl0lvsekmbRdViT0n6WNJZOZy7H+HLfo6ZrQTuAQY3sv8ZwNgM648A6sxsHoCZvWVmLfgZ\nV8b++U94/vlClyIZ9fXhLunjj1v/2nvvHQZzrs5x/PDkyfEmQ4xhIOU6fvADWLw4vvOViFbp3ejW\nyKVBf6CZXSrpBGAOcCLwLNDUT7nuQOr/iPlAxi7MkjoRsi+fn2HzacDdOZQTYEdJU4ClwHAza1vd\nYyZPDm0gBxxQ6JLEr1MnGDgwjHk555zWvfYmm4TsB7mO5r755ni7L8cdXGbMCONdDjoovnOWgDUJ\nQX/6U9pvvz2rNt00twSqrllyCS4N+xwDPGBmSyXl0pc3n/6+xwLPRVVia0jqGG1br70mg/eBnma2\nOGqLeVjS7mb2efqOI0eOXLNcWVlJZUsSCxaT3r2hpqbQpUjOd74Df/97qweXXJNzJpbEs2fPeD/X\nPfYI7UJtLLhAlAonzkBdxmpqaqhpyd9dU1NVAqOAt4DXgI7A14AXczhuf+CJlOeXA5dl2fefwGkZ\n1g9OPUfatmeAvo1cP+N2ynma45oaswMPbL3rPfGE2TvvtN71PvvMbLPNzBYvDs+XLzerrU30krnO\nZ5/ovPcTJ5odemjzjn3zTbNjjll33e9/b3bBBS0vl2tTyHOa41znne8GtI+WOwPb5HBMB6AO6BUF\npdeAXTPs14WQVmbjDNvuAb6f5fzPAPumPN8ypYy9CdVwXTMcF/NbXkTmzTPbZpvWu94hh4QvvtZ0\n3HFmd94Zlp980uzb3070clnns+/b1+yuu8zGjDG7+mobtvPOmfdr5rz361i61Oz115t37GOPmaWX\nYfz45gcr12blG1xyHUT5ScryMmBZDsfUS7oAGA+0B24zsxmSzo22N/T2Oh4Yb2ZfpB4fpfY/gjCX\nTOr6E4DRUTCpljTFzI4EDgGukrSSkLn5XEurZit7220HS5bA8uWhjSJJZmEsx157JXuddBdfvLZn\n2NNPJztfMQYUAAAdm0lEQVS+hUa6r86eDdXV0LUrbL45HbJkfYilm+tmmzX/fZ47N1SrpdpjD88x\n5hKXa8r9ZjGzx4HH09bdkvb8DuCODMcuIwSQ9PX/ZG235NT1DwI5pM8tY+3awZ/+lHuvppZYsCCM\nXm/uRFrNlZr5+Kmn4LrrEr1c1u6r/frB3Wv7mdS/8gq88876+xW6m2um0fnbbgv33+9zmbhEJTg4\nwBXE2WeH3k1JK8RdS6S2uprhhx/OyJdfZvi111JbXZ3YtXLtvlq03VwzBRcpjBdqa4Fl7ly4Y73f\nsS4hWe9cJA0CNjWz+9PWnwQsNbOJSRfOFbECBZf18kM9+WSi+aHWmc/+yy9ZtdFGGbuv5rpfq5s3\nz/OKNZg0CR57DL7//UKXpE3ImhVZ0vPA8Wa2MG39VsC/zGz/Vihf7Mo5K3Ki89mne+KJ0BbQymNq\nhldV8esJE9ZbP6KqiqtzSc3f1ixaFNLQFLp6rhhcdFFol/zlLwtdkpIUZ1bkDdMDC4CZLYoa210R\nyZjxNVpOJMAMGhT/OXPQZvND3XUXfPABXHppfsdttVUy5SlFkyeHLA+uVTTW5rKppA3SV0br/GdQ\nkWkrGV/bdH6ofJJnunWtWgVTphRPpuo2oLHg8hBwq6Q1rcOSNiUkjHwo6YK5/LSVX/RF23CetLhT\nwAAceGC4G2oLZs4Ms3FuvnmhS9JmNFYtNgK4GpgjaW60bnvgNmB40gVz+Wkrv+iLtuE8aUkElw4d\nwniXbbeN97zFqEsXuP76QpeiTcllmuNOwE6EXGF1Zra8NQqWlHJt0M/U5nJFRQWDbrqp/L9424Kv\nvgoN8198Ae1jmgj2/PNhl13g5z+P53yurMXWoC/pO6xNPinCqPeukl6zDMkgXWGt84t+3jxWLVyY\nXGAZNQpOOgl22in+c7vMNtwQttgCPvww9+mcL70U+vTJPpnb7ruHKaKdS0BjXZH/j/UzG28B7A2c\nY2ZPJVu0ZJTrncs65s+HffaBhQuTGSi33XZh4i4fP9G6Zs2CHXYI0yrk4sQT4Ywzwg+BTCZNgiuu\ngH//O74yurIV252LmZ2d5QI7APcTJgNzxah79/AFNGdOmG43TosWhdxl6fmqXPLyvVPMNDo/1e67\nhzYXTwPjEpB3bjEzey9TF2VXRKQwEnnrreM/99SpsOee/mVUCpoKLltuCXV1Rf9ZturgYBebvIOL\npK8D5dW/tRx94xvJnLeAOcVcHr74ApYubTqxaLdurVOeZoplcPDvfw+77Vawgb9tVWMN+v/KsHpz\nYDvgu4mVyBW3qVPjnR/eJWPBAujRY+30BCUq2+DgEWPG5B5cHnoouR9bLqvG7lx+l/bcCJN6vW1m\nK5Irkitq556be28lVzg77RSmMi5xLR4cvGpV6BHnI/NbXWMN+jWZ1ks6WNJpZvazxErlipfftRTO\nwoVQVRXSmORi442TLU8raPHg4JkzQ9tj164xlsrlIqd7Zkl9JV0v6T3CqP23ki2Wi025d7tuS7p1\nC727VsRccfDVV0X7d9LidD+TJ8O++yZQMteUxtpcdgFOB04FFhG6H8vMKlunaK7F7r8fJkyAv/yl\n0CVxcWjfPuTHev996NUrvvP26QPPPhvG0BSZdQYHL17MqilTGHT99bm3t3hwKZjG2lxmAOOAKjOb\nCyDp4lYplYtHnz5w5ZWFLoWLU0OOsTiDyy67hDuiIgwuEALMmmBy+OGwcmXuB//ylyGHmmt1jVWL\nnQh8AdRK+rOkwwlpYFyp2GOPMNZh6dJCl8TFJdcElvlUnTUMpiwFv/xlfm1J223XdHdsl4iswcXM\nHjazU4E9gGeBXwBbSfqTpIGtVUDXAh06hDQwr7wSz/mOPjrktnKFk0twMQup5T/PMQVgsQeX226D\noUPDclWVT/hVIpps0Dez/5rZP8zsGKAnMAUYmnjJXDz69YMXX2z5eT7/HGpqfGbDQvvVr8J0vY35\n9FPo2DFkUc7FHnsUd3CZPj0k7XQlJa8RVmb2qZndamaHJVUgF7P99oO3YujcN21aGOUcV7p31zyb\nbhoyJDemqbQv6XbbDRYvLtoeY8ycGdqFXEnxlq5yd9JJcPLJLT+Pp30pHfkGly5dQsblYtXc4OIJ\nOQuqtHNDuKa1axfPfzAPLqVj3rzyyVr91VdhConevdff1tid1qpVoTH/v/9NrmyuUR5cXG48uJSO\nTz4p2m7FeZs9O9yFdey47vqVK0N13pIlmY97+23o3Bk22ST5MrqMmpzmuNy0icnCkvDBB6EHUq5p\nN1yymqryKacqoeXLoVOn9defcgoceiicd9762+68E8aNg3vvTb58bUS+k4X5nYvLzbbbemApFkcf\nDU8/3fg+5RJYIHNgAfjhD+H22zNv85H5BZdocJE0SNJbkt6RdFmG7ZdImhI9pkqql9RV0i4p66dI\nWippSHTMyZKmS1olqW/a+S6PrvWWj8VJM3Uq1NcXuhQuDltskdtAynxNnRraKkrFgAFh3NUbb6y/\nzYNLwSUWXCS1B/4IDAJ2A06XtGvqPmZ2g5ntY2b7AJcDNWa2xMxmpqzfF1gO/DM6bCpwAlCbdr3d\nCHnQdouuebMkvzNrcMopxT2WweUu11H6+Tr2WHj33fjPm5T27eHss+Fvf1t3vVl4HZ5mv6CS/PLt\nB8wyszlmthK4BxjcyP5nAGMzrD8CqDOzeQBm9paZvZ1hv8HAWDNbaWZzgFlRGRyEwZQvvVToUrg4\nJBVcin2kfiY/+EGYGC2VFN6fzTcvTJkckGxw6Q6k/g+YH61bj6ROQBXwYIbNpwF353C97aJrNHm9\nNmm//Zo/Ur+UqkragsaCy/Ll8NlnzTtvsQWX+npoalKw3r3hvvvWX1/iM3CWgyQHUebTJetY4Dkz\nW6dfoaSO0bb12mtaUoaRI0euWa6srKSysrKZpy8h/frBn/+c/3Fffhka8xcuhA02iL9cLn89e4a0\n+5k8/DA8+ijcc0/+591jD3j88ZaVLU4vvACXXgr/+U+hS9Im1dTUUFNT0+zjkwwuCwi5yBr0ZN07\ni1SnkblK7Ehgspktasb1ekTr1pMaXNqMvfaCurowqCyfvv8zZoS52D2wFI8994RXX828Ld/R+al2\n3x1uuKH55YrbzJmw886FLkWblf7D+6qrrsrr+CTvHV8B+kjqFd2BnAo8mr6TpC5Af+CRDOc4ncxB\nZ83hKcuPAqdJ6ihpR6AP4I0MDTp2DPXTi3KJ0yl88GTxadcue463efOaHVxq58xh+PvvM/KQQxhe\nVUVtdXULChkDzylW0hK7czGzekkXAOOB9sBtZjZD0rnR9luiXY8HxpvZF6nHS+pMaMz/cdr6E4DR\nwJZAtaQpZnakmb0p6T7gTaAeON9HS6b54x9z3rW2upoJo0fTYfp06jt1YmB1de6z/7nCmTsXBubf\nC7+2uprxl13GNZ98ArWhI+awujqAwn3uM2fC976X3zFLloT5i8olQ0EpM7M29Qgv2TVm0rhxdkVF\nhVno1GkGdkVFhU0aN67QRXNN2Wsvs1dfzfuwYQMHrvN5NzyGV1UlUMgc7bKL2dSpOe8+6ayzbFiP\nHnblllvasIED/e81ZtF3Z87ftZ4V2a1nwujRXBP9am1wTV0dI8aM8buXYtehQ7OqxTp89VXG9e2b\n6q2VlNWrw2yaO+2U0+611dWMf+yxcOcFMGFC4e+82jjvr+fWU3RfNG59q1fDF1+sv37yZOjWLe/T\n1WeZI2ZVoVL+tGsXBkLmeP0Jo0evDSyRa+rqmDhmTBKlcznw4OLWU3RfNG59f/sbnH9+bKcbOGQI\nwyoq1ll3RUUFAy68MLZrJMl/EBUfrxZra6ZPh/feg6OOyrrLwCFDGFZXt07V2BUVFQwqkS+aNqFH\nj1hH6TdUHY0YM4b2ixezavlyBo0aVTJVSv6DqPh4yv225vHH4frrm8yqW1tdzcQxY2j/5Zes2mgj\nBlx4Ycl80bQJb74JJ5wQelTFbc4c+Na3wjQLHUrj92dtdTXjf/7z9X8Q3XST/93GJN+U+x5c2ppP\nPoEddwxzpqePlfj8c7j2Wvif//FBk8Xu889h661h2bJk0uvvuy/87ndQQtkr/AdRsjy4NKHNBxeA\nPn1CmpDdd1+7rr4eBg+G7t3hllvKaz6QctW1a8i60NCA/+678LWvxTP74jXXhJQ/N93U8nM1x9Sp\nIR2N/x0WDZ8szDUtPUOyGVx0UZg69n//1/9Dl4rddgsBoMGPftT85KTpTjgBHnqo8Xnqk7JkCRxw\nQOtf18XKg0tblJ4hefRoeOYZuP9+rw4rJc8/D7umTJE0d25IahmHXXcNc9C/8ko858tHQ9oX/5FT\n0kqjtc7FqrZTJya89BIdKiupX7aMgXV19H/1VejSpdBFc821ejXMnx9fcJFg7FhI657cKt56y3OK\nlQEPLm1MbXU140eNWqdXzbCePWH6dPr36lW4grmWWbgQNtsMNt44vnPus09858qHJ6wsC14t1sZk\nTO0yb56PZC51cVaJFZoHl7LgwaWN8ZHMZWrFCjjooEKXIh7duoWeYq6kebVYG+MjmcvI6tVhRsoe\nPUJgKZfgcuuthS6Bi4HfubQxpZ5DyqX46qvQ4L56dbLX+fLLMIOpc3nwQZRtkI9kLiNbbRUGHG6z\nTXLXOO+8MPD24ouTu4Yrej5CvwkeXFxZ2Xdf+POfQy6wpDz+eBix/9xzyV3DFT0foe9cW9KzZ6zZ\nkTM67LCQTfuDD5K9jisrHlycK2U9e4acYkneVWy4YZii4ZFHkrtGgyefhM8+S/46LnEeXJwrZbvt\nFoLLWWcle50TTwy5xpL2ve+F3GKu5Hlwca6UnXcenHwybL99stcZNAi23DLZnmmffQZLl4au1a7k\n+TgX50rd3LnJB5fOneHuu5O9xttvh15p7fw3bznw4OJcCautrmbC1VfTYcUK6quqGDhkSOl2K/e0\nL2XFg4tzJWq9qX3nzWNYtFySAWbmTNh550KXwsXE7z+dK1EZk5DW1ZVuEtLeveHQQwtdChcTv3Nx\nrkSVXRLSs88udAlcjDy4OFeiCpGEtPbRR5lw3nl0qKigfuONS7uNxyXKg4tzJWrgkCEMq6tbp2rs\niooKBiWUhLS2uprxF1/MNe+/H7IxQ2m38bhEJZpbTNIg4EagPfBXM/tN2vZLgDOjpx2AXYEtga2B\ne1J27Q2MMLPRkrYA7gV2AOYAp5jZEkm9gBnAW9Ex/zGz8zOUyXOLubLRmklIh1dV8esJE9ZbP6Kq\niqufeCKRa7rikW9uscTuXCS1B/4IHAEsAF6W9KiZzWjYx8xuAG6I9j8GuMjMlgBLgH2i9e2i4/8Z\nHTYUmGhmv5V0WfR8aLRtlpkVaG5W51pf/6OPbrW7hrJr43GJSrK3WD/Cl/0cM1tJuBMZ3Mj+ZwBj\nM6w/Aqgzs4bsfMcBd0TLdwDHx1Re51wjEm3jGTcO3nyz5edxRSPJ4NIdSE3XOj9atx5JnYAq4MEM\nm08DUocGb21mH0XLHxGq0BrsKGmKpBpJZTItn3PFIeNEc716xTPR3OjRMGdOy8/jikaSDfr5NGwc\nCzwXVYmtIaljtO2yjBcwM0kN13kf6GlmiyX1BR6WtLuZfd6Msjvn0jRUv41IaeMZFFcbj4/OLztJ\nBpcFQM+U5z0Jdy+ZnEbmKrEjgclmtihl3UeStjGzDyVtCywEMLMVwIpo+VVJdUAf4NX0k44cOXLN\ncmVlJZWVlTm+JOfatkTaeJYvh4ULoVeveM/rWqSmpoaamppmH59YbzFJHYCZwOGEu4qXgNNTG/Sj\n/boA7wI9zOyLtG33AI+b2R0p634LfGJmv5E0FOhqZkMlbQksNrNVknoDtcAeGe6GvLeYc8Xk9dfh\nzDNh2rRCl8Q1omh6i5lZvaQLgPGErsi3mdkMSedG22+Jdj0eGJ8hsHQmNOb/OO3Uo4D7JJ1D1BU5\nWt8f+B9JK4HVwLnpgcU5V4S8SqwsJTrOpRj5nYtzCVi9OkyD3D1jn53GTZ4MH34IPhCzqOV75+LB\nxTnXchMmwC9+Aa+9BhtskPNhtdXVTBg9mg5ffUX9hht6OpkiVjTVYs65NmTAgDBh2Y03wqWX5nTI\nelMG4OlkyonfuTjn4jFrFuy/P0yZAj17Nrm7p5MpLfneufh8Ls65eOy0E1xwQagea0pdHR2ypI3x\ndDLlwYOLcy4+l10W7lwmTcq8felSuOQS2G8/6leuzLhLklMGuNbjbS7OufhsvDE8/TS1r7/OhKqq\ntQ31P/sZ/RcuhBEj4KijYNo0Bk6ezLC0NpckpwxwrcuDi3MuVrXTpoV5X1Ib6mtqoKKC/uPGwb77\nAgmnk3EF5w36zrlYeUN9efIGfedcQfm8Lw48uDjnYpbovC+uZHhwcc7FKuO8LxUV8cz74kqGt7k4\n52JXW13NxJSG+gHeUF/yPLdYEzy4OOdc/rxB3znnXMF5cHHOORc7Dy7OOedi58HFOedc7Dy4OOec\ni50HF+ecc7Hz4OKccy52Hlycc87FzoOLc8652Hlwcc45FzsPLs4552LnwcU551zsPLg455yLnQcX\n55xzsfPg4pxzLnaJBhdJgyS9JekdSZdl2H6JpCnRY6qkekldJe2Ssn6KpKWShkTHbCFpoqS3JU2Q\n1DXlfJdH13pL0sAkX5tzzrnsEgsuktoDfwQGAbsBp0vaNXUfM7vBzPYxs32Ay4EaM1tiZjNT1u8L\nLAf+GR02FJhoZjsDT0XPkbQbcGp0rUHAzZLK7s6spqam0EVokVIufymXHbz8hVbq5c9Xkl++/YBZ\nZjbHzFYC9wCDG9n/DGBshvVHAHVmNi96fhxwR7R8B3B8tDwYGGtmK81sDjArKkNZKfU/0FIufymX\nHbz8hVbq5c9XksGlOzAv5fn8aN16JHUCqoAHM2w+Dbg75fnWZvZRtPwRsHW0vF10jSav55xzLllJ\nBpd8Jqo/FnjOzJakrpTUMdp2f8YLmFkT18mnDM455+JiZok8gP2BJ1KeXw5clmXffwKnZVg/OPUc\n0bq3gG2i5W2Bt6LlocDQlP2eAPbLcE7zhz/84Q9/5P/IJwYo+sKNnaQOwEzgcOB94CXgdDObkbZf\nF+BdoIeZfZG27R7gcTO7I2Xdb4FPzOw3koYCXc1saNSgfzehnaU78CSwkyX1Ap1zzmXVIakTm1m9\npAuA8UB74DYzmyHp3Gj7LdGuxwPjMwSWzoTG/B+nnXoUcJ+kc4A5wCnR+d6UdB/wJlAPnO+BxTnn\nCiOxOxfnnHNtV9mNA8mmqQGdxU7SHElvRINKXyp0eZoi6XZJH0mamrIu6wDYYpOl/CMlzU8Z3Duo\nkGVsjKSekp6RNF3StFwGIReTRspf9J+BpI0kvSjpNUlvSrouWl8q73228uf13reJO5doQOdMQjXb\nAuBlMrT/FDNJs4F9zezTQpclF5IOBv4L/N3M9ozW/Rb42Mx+GwX4zc1saCHLmU2W8l8JfG5mvy9o\n4XIgaRtCx5fXJG0CTCZUQf+AEvgMGin/KZTAZyCpk5ktj9qenwMuIYzRK/r3HrKW/3DyeO/byp1L\nvgM6i5UKXYBcmdmzwOK01dkGwBadLOWHEvkMzOxDM3stWv4vMIPQ0aUkPoNGyg8l8BmY2fJosSOh\nzXkxJfLeQ9byQx7vfVsJLjkP6CxiBjwp6RVJ6Z0cSkW2AbCl5EJJr0u6rVirNdJJ6gXsA7xICX4G\nKeV/IVpV9J+BpHaSXiO8x8+Y2XRK6L3PUn7I471vK8GlHOr+DoxyrR0J/CyqtilZOQyALUZ/AnYE\nvgF8APyusMVpWlSl9CDwczP7PHVbKXwGUfkfIJT/v5TIZ2Bmq83sG0APoL+kQ9O2F/V7n6H8leT5\n3reV4LIA6JnyvCfrpoopemb2QfTvIsKg01LMm/ZRVJeOpG2BhQUuT17MbKFFgL9S5J+BpA0IgeVO\nM3s4Wl0yn0FK+e9qKH+pfQZmthSoJiTgLZn3vkFK+b+Z73vfVoLLK0AfSb2ilDKnAo8WuEw5k9RJ\n0qbRcmdgIDC18aOK0qPA96Pl7wMPN7Jv0Ym+EBqcQBF/BpIE3Aa8aWY3pmwqic8gW/lL4TOQtGVD\nlZGkjYEBwBRK573PWP6GwBhp8r1vE73FACQdCdzI2gGd1xW4SDmTtCNrpxzoAPyj2MsvaSxwCLAl\nod72V8AjwH3A9kQDYC0tn1yxyFD+K4FKQpWAAbOBc1Pq0IuKpIOAWuAN1la/XE7IlFH0n0GW8l8B\nnE6RfwaS9iQ02LeLHnea2fWStqA03vts5f87ebz3bSa4OOecaz1tpVrMOedcK/Lg4pxzLnYeXJxz\nzsXOg4tzzrnYeXBxzjkXOw8uzjnnYufBxZUVSTWS9m2F6wyJ0pHf2cLzzInGP+R73CGSvh3X9SSd\nHL2ep5pxzi6Szsv3OFfePLi4ctPsgVtRevFcnQccYWZnNfd6keaW91DggBivdw7wIzM7vBnn3Bw4\nP9+DJPn3TxnzD9e1uigNzwxJt0YTQY2XtFG0bc2dR5SGYna0fLakh6NJlmZLukDSJZJelfQfSZun\nXOKsaDKjqZK+FR3fWWECsBejY45LOe+j0S/2iRnKenF0nqmSfh6t+zPQG3hC0kVp++8eXWNKlD22\nIlr/3ZT1f870xZptH4WJ7iYrTN40UdIOwLnAL6J9D5S0laQHJL0UPQ6Iju0WvWfTJP2FDCnTJf0K\nOBC4XdJvFDLiXh+d53VJP4n220TSk1FZ3mh4DwlTj1dEZfltdFf1r5Tz/1HS96PlOZJGSZoMnCxp\noKTno3Pep5DeiGif6dH1r8/2t+SKmJn5wx+t+gB6ASuBvaLn9wJnRsvPAH2j5S2B2dHy2cA7QOdo\n/VLgJ9G23xOy5gLUALdEywcDU6Pla1Ou0ZUweVyn6LzzgK4ZyrkvIf3IxtF1pwF7R9tmA1tkOGY0\ncEa03AHYCNiVkFeqfbT+ZuCs1PNk2wfYCpgL7NBQ9ujfK4GLU657NyFzNoT0Im+mlGd4tHwUsDpL\nuVPf958Aw6LlDQmT6/UipE7aNOWzeSda3qHhfY6eVwL/Snk+Bvheyuu9JOUck4CNo+eXASOi9+Ot\nlOM3K/TfrD/yf+RTDeBcnGab2RvR8mTCl1dTnjGzZcAySUuAhl/HU4G9omUDxkKY8EvSZpK6EJJ9\nHivpkmi/DQlfwgZMtMw5ng4CHjKzLwAkPQT0B15vpIz/AYZJ6hEdO0vS4YRA9YokCMHqw5RjRJjl\nL3WfjaJ99gNqzey96DUtSTuuwRHArtGxAJtGdwEHE5IMYmaPSco0AVq6gcCekk6Knm8G7ETIJH6d\nwnQPq4HtJH2NDHdDTbg3+nd/YDfg+ajcHYHnCT8cvpR0GzAuergS48HFFcpXKcurCF+mAPWsra7d\niHWlHrM65flqGv9bbmhnONHM3kndIGk/YFkjx6V+cYom2kjMbKykF4BjgMcknRttusPMrmjs2Ez7\nSDqmiWNSy7afma1IO75hW74uMLN1qgklnU242+hrZquiKsv0zwjW/QwhBNNUqe/3RDM7I/0EkvoR\nAu5JwAXRsish3ubiikXDF+Ac4JvR8kmZd816bMPyqbAms+4SM/sMGA8MWbOTtE+GY9M9CxwvaePo\nLuD4aF32gkg7mtlsMxtDyAK9J/AUcJKkraJ9tpC0fcph1sg+LxAma+rVsD465nNg05RzTEh7fXtH\ni7XAGdG6IwmN700ZD5yvqIODpJ0ldSLcwSyMAsuhhOqwTGV5D9hNUkeF1O2HZbnOi8CBKe1SnSX1\nid7rrmb2OHAxsHeW410R8zsXVyjpdwANz28A7osakatT1qfP3Je+nLrfl5JeJfx9/zBafzVwo6Q3\nCD+q3iXMaZ51RkAzmyLp/whp6gH+YmYNVWLZ7mBOkXQWoU3pA+AaM1siaTgwIWqkX0noXTU35Voz\nMu1jZi9F78VD0fqPgCpCleADkgYTftkPAf5X0uvR654UXeMqYKyk0wlVTu9lKXeqvxKqKV9VuPVZ\nSAis/wD+Fb2HrxDmtcfMPpH0b0lTgcfM7DJJ9xHaqGYDr2a6iJktiu6GxkraMFo9jBCsHlHo5CHg\nFzmU2RUZT7nvnHMudl4t5pxzLnYeXJxzzsXOg4tzzrnYeXBxzjkXOw8uzjnnYufBxTnnXOw8uDjn\nnIudBxfnnHOx+/9028eGed0R6gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1edde3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tic_total = time.time()\n",
    "features=feature_selection_backward(xgbclassifier, params, X, y, diagonistics=True, SEED=42, num_rows=X.shape[0], drop_features_percent=0.2, feature_num_thresh=10, n_cv_rounds=5, auc_prec=1000, auc_prec2=10000)\n",
    "elapsed_total = time.time() - tic_total\n",
    "print ('Time elapsed = {}'.format(elapsed_total/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
