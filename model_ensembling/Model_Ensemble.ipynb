{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "import itertools\n",
    "import json\n",
    "import scipy as sp\n",
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from functools import partial\n",
    "from operator import itemgetter\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import cross_validation, linear_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "#plt.rc('figure', figsize=(10, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Prediction of test data and CV-predictoin of train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145231L,)\n",
      "Model-1: The min and max of model sgd_0p771702_wl_ ypred_train is: 0.002001, 0.987034\n",
      "Model-1: The AUC score for model sgd_0p771702_wl_ is: 0.771702\n",
      "\n",
      "Model-2: The min and max of model sgd_0p770356_wl_ ypred_train is: 0.003360, 0.976353\n",
      "Model-2: The AUC score for model sgd_0p770356_wl_ is: 0.770356\n",
      "\n",
      "Model-3: The min and max of model sgd_0p769531_wl_ ypred_train is: 0.021350, 0.989736\n",
      "Model-3: The AUC score for model sgd_0p769531_wl_ is: 0.769532\n",
      "\n",
      "Model-4: The min and max of model svm-0p752773_wl_ ypred_train is: 0.000000, 0.950000\n",
      "Model-4: The AUC score for model svm-0p752773_wl_ is: 0.752773\n",
      "\n",
      "Model-5: The min and max of model rf-335_ ypred_train is: 0.001132, 0.897290\n",
      "Model-5: The AUC score for model rf-335_ is: 0.770027\n",
      "\n",
      "Model-6: The min and max of model rf-all_ ypred_train is: 0.001167, 0.892383\n",
      "Model-6: The AUC score for model rf-all_ is: 0.768094\n",
      "\n",
      "Model-7: The min and max of model xgb-665_ ypred_train is: 0.017837, 0.931054\n",
      "Model-7: The AUC score for model xgb-665_ is: 0.772898\n",
      "\n",
      "Model-8: The min and max of model xgb-933_ ypred_train is: 0.020846, 0.927963\n",
      "Model-8: The AUC score for model xgb-933_ is: 0.773977\n",
      "\n",
      "Model-9: The min and max of model xgb-all_ ypred_train is: 0.104158, 0.751833\n",
      "Model-9: The AUC score for model xgb-all_ is: 0.760597\n",
      "\n",
      "Model-10: The min and max of model xgb_0p770751_wl_ ypred_train is: 0.036896, 0.863946\n",
      "Model-10: The AUC score for model xgb_0p770751_wl_ is: 0.770751\n",
      "\n",
      "Model-11: The min and max of model xgb_lr_0p777824_wl_ ypred_train is: 0.003393, 0.979887\n",
      "Model-11: The AUC score for model xgb_lr_0p777824_wl_ is: 0.777824\n",
      "\n",
      "Model-12: The min and max of model xgb_lr_0p777125_50Segments_wl_ ypred_train is: 0.003243, 0.992029\n",
      "Model-12: The AUC score for model xgb_lr_0p777125_50Segments_wl_ is: 0.777126\n",
      "\n",
      "Model-13: The min and max of model xgb_lr_0p776415_wl_ ypred_train is: 0.002763, 0.977213\n",
      "Model-13: The AUC score for model xgb_lr_0p776415_wl_ is: 0.776415\n",
      "\n",
      "Model-14: The min and max of model xgb_0p784886_wl_ ypred_train is: 0.002843, 0.971649\n",
      "Model-14: The AUC score for model xgb_0p784886_wl_ is: 0.784887\n",
      "\n",
      "Model-15: The min and max of model xgb_0p785604_wl_ ypred_train is: 0.000559, 0.987909\n",
      "Model-15: The AUC score for model xgb_0p785604_wl_ is: 0.785604\n",
      "\n",
      "Model-16: The min and max of model xgb_0p785120_wl_ ypred_train is: 0.000606, 0.987891\n",
      "Model-16: The AUC score for model xgb_0p785120_wl_ is: 0.785120\n",
      "\n",
      "Model-17: The min and max of model xgb_0p784916_wl_ ypred_train is: 0.000430, 0.986762\n",
      "Model-17: The AUC score for model xgb_0p784916_wl_ is: 0.784917\n",
      "\n",
      "Model-18: The min and max of model xgb_0p785155_wl_ ypred_train is: 0.000519, 0.987983\n",
      "Model-18: The AUC score for model xgb_0p785155_wl_ is: 0.785156\n",
      "\n",
      "Model-19: The min and max of model xgb_0p785468_wl_ ypred_train is: 0.000414, 0.982580\n",
      "Model-19: The AUC score for model xgb_0p785468_wl_ is: 0.785468\n",
      "\n",
      "Model-20: The min and max of model xgb_0p785787_wl_ ypred_train is: 0.000401, 0.983485\n",
      "Model-20: The AUC score for model xgb_0p785787_wl_ is: 0.785787\n",
      "\n",
      "Model-21: The min and max of model xgb_0p785890_wl_ ypred_train is: 0.000512, 0.985166\n",
      "Model-21: The AUC score for model xgb_0p785890_wl_ is: 0.785890\n",
      "\n",
      "Model-22: The min and max of model xgb_0p786040_wl_ ypred_train is: 0.000441, 0.984607\n",
      "Model-22: The AUC score for model xgb_0p786040_wl_ is: 0.786041\n",
      "\n",
      "Model-23: The min and max of model xgb_0p786290_wl_ ypred_train is: 0.000436, 0.985556\n",
      "Model-23: The AUC score for model xgb_0p786290_wl_ is: 0.786291\n",
      "\n",
      "Model-24: The min and max of model xgbmeta_0p793611_wl_ ypred_train is: 0.001231, 0.993303\n",
      "Model-24: The AUC score for model xgbmeta_0p793611_wl_ is: 0.793612\n",
      "\n",
      "Model-25: The min and max of model xgbmeta_0p793971_wl_ ypred_train is: 0.001790, 0.993772\n",
      "Model-25: The AUC score for model xgbmeta_0p793971_wl_ is: 0.793971\n",
      "\n",
      "Model-26: The min and max of model xgb_Oct192015134751_AUC_0p787695_sl_ ypred_train is: 0.004872, 0.961161\n",
      "Model-26: The AUC score for model xgb_Oct192015134751_AUC_0p787695_sl_ is: 0.787696\n",
      "\n",
      "Model-27: The min and max of model xgb_Oct192015065533_AUC_0p787632_sl_ ypred_train is: 0.004168, 0.957202\n",
      "Model-27: The AUC score for model xgb_Oct192015065533_AUC_0p787632_sl_ is: 0.787633\n",
      "\n",
      "Model-28: The min and max of model xgb_Oct192015133017_AUC_0p787608_sl_ ypred_train is: 0.002859, 0.969335\n",
      "Model-28: The AUC score for model xgb_Oct192015133017_AUC_0p787608_sl_ is: 0.787608\n",
      "\n",
      "Model-29: The min and max of model xgb_Oct192015101525_AUC_0p787437_sl_ ypred_train is: 0.003693, 0.962979\n",
      "Model-29: The AUC score for model xgb_Oct192015101525_AUC_0p787437_sl_ is: 0.787438\n",
      "\n",
      "Model-30: The min and max of model xgb_Oct192015120324_AUC_0p787252_sl_ ypred_train is: 0.002629, 0.976089\n",
      "Model-30: The AUC score for model xgb_Oct192015120324_AUC_0p787252_sl_ is: 0.787253\n",
      "\n",
      "Model-31: The min and max of model xgb_Oct192015085532_AUC_0p787197_sl_ ypred_train is: 0.005716, 0.945443\n",
      "Model-31: The AUC score for model xgb_Oct192015085532_AUC_0p787197_sl_ is: 0.787198\n",
      "\n",
      "Model-32: The min and max of model xgb_Oct192015040605_AUC_0p786733_sl_ ypred_train is: 0.005786, 0.948136\n",
      "Model-32: The AUC score for model xgb_Oct192015040605_AUC_0p786733_sl_ is: 0.786734\n",
      "\n",
      "Model-33: The min and max of model xgb_Oct192015051026_AUC_0p786338_sl_ ypred_train is: 0.007389, 0.937883\n",
      "Model-33: The AUC score for model xgb_Oct192015051026_AUC_0p786338_sl_ is: 0.786339\n",
      "\n",
      "Model-34: The min and max of model xgb_Oct192015120134_AUC_0p785606_sl_ ypred_train is: 0.003580, 0.965678\n",
      "Model-34: The AUC score for model xgb_Oct192015120134_AUC_0p785606_sl_ is: 0.785606\n",
      "\n",
      "Model-35: The min and max of model xgb_Oct192015052747_AUC_0p781263_sl_ ypred_train is: 0.000004, 0.999799\n",
      "Model-35: The AUC score for model xgb_Oct192015052747_AUC_0p781263_sl_ is: 0.781264\n",
      "\n",
      "Model-36: The min and max of model xgb_Oct192015065922_AUC_0p780004_sl_ ypred_train is: 0.000024, 0.998520\n",
      "Model-36: The AUC score for model xgb_Oct192015065922_AUC_0p780004_sl_ is: 0.780005\n",
      "\n",
      "Model-37: The min and max of model xgb_Oct192015154017_AUC_0p787790_sl_ ypred_train is: 0.003885, 0.965109\n",
      "Model-37: The AUC score for model xgb_Oct192015154017_AUC_0p787790_sl_ is: 0.787790\n",
      "\n",
      "Model-38: The min and max of model meta_xgb_Oct192015184228_AUC_0p794324_sl_ ypred_train is: 0.002454, 0.992132\n",
      "Model-38: The AUC score for model meta_xgb_Oct192015184228_AUC_0p794324_sl_ is: 0.794325\n",
      "\n",
      "Model-39: The min and max of model meta_xgb_Oct192015184936_AUC_0p794619_sl_ ypred_train is: 0.002528, 0.991142\n",
      "Model-39: The AUC score for model meta_xgb_Oct192015184936_AUC_0p794619_sl_ is: 0.794620\n",
      "\n",
      "Model-40: The min and max of model meta_xgb_Oct192015185918_AUC_0p794108_sl_ ypred_train is: 0.001992, 0.992972\n",
      "Model-40: The AUC score for model meta_xgb_Oct192015185918_AUC_0p794108_sl_ is: 0.794108\n",
      "\n",
      "((145231L, 40L), (145232L, 40L))\n"
     ]
    }
   ],
   "source": [
    "path_to_results = 'C:/Users/HZ/Dropbox/Bio_Physics_JailBreak/Kaggle/Final Prediction/'\n",
    "\n",
    "\n",
    "test_ID = pickle.load(open(path_to_results+'xtest_ID.pkl','rb'))    \n",
    "y = pickle.load(open(path_to_results+'ytrain2.dat','rb'))  # ground-truth label of training data\n",
    "print(y.shape)\n",
    "\n",
    "results=[#\"pa-283_\",\"pa-335_\",\"pa-0p75277_wl_\",\n",
    "#         \"sgd-283_\",\"sgd-335_\",'sgd-0p768996_wl_','sgd-0p770277_wl_',\n",
    "#         'sgd_0p784555_wl_',\n",
    "         'sgd_0p771702_wl_',\n",
    "         'sgd_0p770356_wl_','sgd_0p769531_wl_',\n",
    "         'svm-0p752773_wl_',\n",
    "#         \"svm-283_\",\"svm-335_\",\n",
    "         \"rf-335_\",\"rf-all_\",\n",
    "         \"xgb-665_\",\"xgb-933_\",\"xgb-all_\",\"xgb_0p770751_wl_\",\n",
    "        \"xgb_lr_0p777824_wl_\",\"xgb_lr_0p777125_50Segments_wl_\",\"xgb_lr_0p776415_wl_\",\n",
    "         \"xgb_0p784886_wl_\",\"xgb_0p785604_wl_\",\"xgb_0p785120_wl_\",\"xgb_0p784916_wl_\",\n",
    "        \"xgb_0p785155_wl_\",\"xgb_0p785468_wl_\",\"xgb_0p785787_wl_\",\"xgb_0p785890_wl_\",\"xgb_0p786040_wl_\",\"xgb_0p786290_wl_\",\n",
    "#        \"xgb_0p806151_wl_\",\n",
    "        \"xgbmeta_0p793611_wl_\",\n",
    "        \"xgbmeta_0p793971_wl_\"]\n",
    "\n",
    "# addition models from Saifeng\n",
    "model_name1  = 'xgb_Oct192015134751_AUC_0p787695_sl_'\n",
    "model_name2  = 'xgb_Oct192015065533_AUC_0p787632_sl_'\n",
    "model_name3  = 'xgb_Oct192015133017_AUC_0p787608_sl_'\n",
    "model_name4  = 'xgb_Oct192015101525_AUC_0p787437_sl_'\n",
    "model_name5  = 'xgb_Oct192015120324_AUC_0p787252_sl_'\n",
    "model_name6  = 'xgb_Oct192015085532_AUC_0p787197_sl_'\n",
    "model_name7  = 'xgb_Oct192015040605_AUC_0p786733_sl_'\n",
    "model_name8  = 'xgb_Oct192015051026_AUC_0p786338_sl_'\n",
    "model_name9  = 'xgb_Oct192015120134_AUC_0p785606_sl_'\n",
    "model_name10 = 'xgb_Oct192015052747_AUC_0p781263_sl_'\n",
    "model_name11 = 'xgb_Oct192015065922_AUC_0p780004_sl_'\n",
    "model_name12 = 'xgb_Oct192015154017_AUC_0p787790_sl_'\n",
    "model_name13 = 'meta_xgb_Oct192015184228_AUC_0p794324_sl_'\n",
    "model_name14 = 'meta_xgb_Oct192015184936_AUC_0p794619_sl_'\n",
    "model_name15 = 'meta_xgb_Oct192015185918_AUC_0p794108_sl_'\n",
    "\n",
    "model_saifeng=[model_name1,model_name2,model_name3,model_name4,model_name5,\n",
    "               model_name6,model_name7,model_name8,model_name9,model_name10,\n",
    "               model_name11,model_name12,model_name13,model_name14,model_name15]\n",
    "results.extend(model_saifeng)\n",
    "\n",
    "nameypreds_train = 'ypredtrain.pkl'\n",
    "nameypreds_test = 'ypredtest.pkl'\n",
    "\n",
    "preds_train=[]\n",
    "preds_test =[]\n",
    "\n",
    "for i, model in enumerate(results):\n",
    "    ypred_train = list(pickle.load(open(path_to_results + model + nameypreds_train, 'rb')))\n",
    "    print('Model-%d: The min and max of model %s ypred_train is: %f, %f'%(i+1, model,np.array(ypred_train).min(),np.array(ypred_train).max()))\n",
    "    print('Model-%d: The AUC score for model %s is: %f\\n'%(i+1, model,metrics.roc_auc_score(y, ypred_train)))\n",
    "    preds_train.append(ypred_train)\n",
    "    preds_test.append(list(pickle.load(open(path_to_results + model + nameypreds_test, 'rb'))))\n",
    "        \n",
    "preds_train=np.array(preds_train).T\n",
    "preds_test=np.array(preds_test).T    \n",
    "print(preds_train.shape, preds_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#preds_train = pd.DataFrame(preds_train)\n",
    "#preds_test  = pd.DataFrame(preds_test)\n",
    "#y = pd.Series(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ModelEnsembler(object):\n",
    "    \"\"\"\n",
    "    Implement stacking to combine several models.\n",
    "    There are several methods to do stacking.\n",
    "    1. BaggingEnsembler: take the simple average of level-0 predictions on the test set\n",
    "    2. LSEnsembler: linear regression to minimize the least square lost of a linear combination of model predictions on the train set. \n",
    "             the optimized coefficients are used to combine model predictions on the test set.\n",
    "    3. AUCEnsember: again, linear combination of model predictions on the train set. \n",
    "                    But we search for the coefficients to maximize AUC score on the train set.\n",
    "                    The optimized coefficients are further used to combine predictions on the train set.\n",
    "    4. StackingEnsembler: use a level-1 model to train the level-0 predictions on the train set. \n",
    "                          Then use the trained level-1 model to compute predictions on the test set.               \n",
    "    \"\"\"\n",
    "    def __init__(self,generalizer=None):\n",
    "        self.coef_ = 0\n",
    "        self.generalizer = linear_model.RidgeCV(alphas=np.linspace(0, 1000), cv=10) # level-1 model\n",
    "        \n",
    "    # 1. BaggingEnsembler   \n",
    "    def Bagging(self, preds_test):  # preds_test in the form of N x M, N: # of samples, M: # of level-0 model preds.\n",
    "        return np.mean(preds_test, axis=1)   # average over M model preds\n",
    "    \n",
    "    # 2. LSEnsembler\n",
    "    def fit_LS(self, X, y): # X = preds_train in the form of N x M\n",
    "        self.coef_ = sp.optimize.nnls(X, y)[0] #argmin_w||Xw-y||_2 solver for w\n",
    "        self.coef_ = np.array(map(lambda x: x/sum(self.coef_), self.coef_)) # normalized\n",
    "\n",
    "    def predict_proba(self, X):  # X = preds_test in the form of N x M \n",
    "        return sp.dot(X, self.coef_)\n",
    "    \n",
    "    def score(self, y, ypreds):  # AUC score\n",
    "        fpr, tpr, _ = roc_curve(y, ypreds)\n",
    "        return auc(fpr, tpr)\n",
    "    \n",
    "    def _auc_loss(self, coef, X, y):\n",
    "        fpr, tpr, _ = roc_curve(y, sp.dot(X, coef))\n",
    "        return -auc(fpr, tpr)\n",
    "    \n",
    "    # 3. AUCEnsembler\n",
    "    def fit_AUC(self, X, y):# X = preds_train, find coef to maximize AUC\n",
    "        lr = linear_model.LinearRegression()\n",
    "#        lr = linear_model.LinearRegression(fit_intercept=False)\n",
    "\n",
    "                \n",
    "        auc_partial = partial(self._auc_loss, X=X, y=y)  # return a new function of coef\n",
    "#       initial_coef = lr.fit(X, y).coef_                # initial guess\n",
    "        initial_coef = [1/float(X.shape[1])]*X.shape[1]\n",
    "        print ('Initial coefficient of AUC_fit:')\n",
    "        print(initial_coef)\n",
    "        bnds = tuple([(0,1) for i in range(len(initial_coef))])\n",
    "        \n",
    "        \n",
    "        #res = minimize(auc_partial, initial_coef,  constraints=cons, method='SLSQP', options={'disp': True})\n",
    "        res = minimize(auc_partial, initial_coef,  bounds=bnds, method='SLSQP', options={'disp': True})\n",
    "        self.coef_=res.x\n",
    "        \n",
    "    # 4. StackingEnsembler: train level-1 model on level-0 predictions of train set, then compute predictions of test set\n",
    "    def stackingEnsembler(self, preds_train, y, preds_test):\n",
    "        self.generalizer.fit(preds_train, y)\n",
    "        print('The coef from stacking is :')\n",
    "        print(self.generalizer.coef_)\n",
    "        print ('The optimal alpha is %d'%self.generalizer.alpha_)\n",
    "        return self.generalizer.predict(preds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate submission files\n",
    "def save_results(test_ID, predictions, filename):\n",
    "    \"\"\"Given a vector of predictions, save results in CSV format.\"\"\"\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(\"ID,target\\n\")\n",
    "        for i in range(len(test_ID)):\n",
    "            f.write(\"%d,%f\\n\" % (test_ID[i], predictions[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145231L, 40L)"
      ]
     },
     "execution_count": 608,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16845507694037137"
      ]
     },
     "execution_count": 609,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_train[100,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 Greedy Bagging with replacememnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def greedy_bagging(preds_train, preds_test, y, nth=20):\n",
    "    m,n = preds_train.shape\n",
    "    bag_count=np.zeros(n) # to store the count of each model\n",
    "    ytrain_accum = np.zeros(m) # to store the sum of selected ypred_train\n",
    "    \n",
    "    hist_auc=[]\n",
    "    \n",
    "    num_sel_models = 0\n",
    "    best_auc = -9999\n",
    "    \n",
    "    true_best = -9999\n",
    "    \n",
    "    yauc = np.zeros(n)\n",
    "    ytemp = np.zeros((m,n))\n",
    "    \n",
    "    while num_sel_models<nth:\n",
    "        for i in range(n):\n",
    "            ytemp[:,i] = (ytrain_accum*num_sel_models + preds_train[:,i])/float(num_sel_models+1)           \n",
    "            yauc[i] = metrics.roc_auc_score(y, ytemp[:,i])\n",
    "        \n",
    "        max_ind = np.argmax(yauc)\n",
    "        print('The best auc in round %d: %9.7f'%(num_sel_models,yauc[max_ind]))\n",
    "        \n",
    "        if yauc[max_ind]>true_best:\n",
    "            true_best=yauc[max_ind]\n",
    "            count_best=np.copy(bag_count)\n",
    "                \n",
    "        if yauc[max_ind]>best_auc*0.95:\n",
    "            best_auc = yauc[max_ind]\n",
    "            ytrain_accum = ytemp[:,max_ind]\n",
    "            num_sel_models += 1\n",
    "            bag_count[max_ind] += 1\n",
    "            \n",
    "            hist_auc.append(best_auc)\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    plt.gca()\n",
    "    plt.plot(range(len(hist_auc)), hist_auc, 'ro--')\n",
    "    plt.legend(loc='best',fontsize='medium')\n",
    "    plt.xlabel('# of models')\n",
    "    plt.ylabel('AUC score')\n",
    "    plt.ylim([min(hist_auc) - .001, max(hist_auc) + .001])\n",
    "\n",
    "    str1=time.strftime(\"%b%d%Y_%H%M%S\", time.localtime())\n",
    "    \n",
    "    plt.savefig(path_to_results+'greedy-model-ensembling_'+str1+'.png')\n",
    "    plt.show()\n",
    "    \n",
    "    return np.dot(preds_test,bag_count/float(num_sel_models)), bag_count, true_best, count_best,hist_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best auc in round 0: 0.7946198\n",
      "The best auc in round 1: 0.7956130\n",
      "The best auc in round 2: 0.7956625\n",
      "The best auc in round 3: 0.7957415\n",
      "The best auc in round 4: 0.7957617\n",
      "The best auc in round 5: 0.7957709\n",
      "The best auc in round 6: 0.7957957\n",
      "The best auc in round 7: 0.7958090\n",
      "The best auc in round 8: 0.7958135\n",
      "The best auc in round 9: 0.7958072\n",
      "The best auc in round 10: 0.7957900\n",
      "The best auc in round 11: 0.7957968\n",
      "The best auc in round 12: 0.7958109\n",
      "The best auc in round 13: 0.7958157\n",
      "The best auc in round 14: 0.7958179\n",
      "The best auc in round 15: 0.7958138\n",
      "The best auc in round 16: 0.7958104\n",
      "The best auc in round 17: 0.7958143\n",
      "The best auc in round 18: 0.7958199\n",
      "The best auc in round 19: 0.7958157\n",
      "The best auc in round 20: 0.7958162\n",
      "The best auc in round 21: 0.7958156\n",
      "The best auc in round 22: 0.7958196\n",
      "The best auc in round 23: 0.7958185\n",
      "The best auc in round 24: 0.7958177\n",
      "The best auc in round 25: 0.7958170\n",
      "The best auc in round 26: 0.7957798\n",
      "The best auc in round 27: 0.7957061\n",
      "The best auc in round 28: 0.7957161\n",
      "The best auc in round 29: 0.7957320\n",
      "The best auc in round 30: 0.7957445\n",
      "The best auc in round 31: 0.7957502\n",
      "The best auc in round 32: 0.7957588\n",
      "The best auc in round 33: 0.7957655\n",
      "The best auc in round 34: 0.7957733\n",
      "The best auc in round 35: 0.7957811\n",
      "The best auc in round 36: 0.7957839\n",
      "The best auc in round 37: 0.7957883\n",
      "The best auc in round 38: 0.7957921\n",
      "The best auc in round 39: 0.7957956\n",
      "The best auc in round 40: 0.7957979\n",
      "The best auc in round 41: 0.7957997\n",
      "The best auc in round 42: 0.7958027\n",
      "The best auc in round 43: 0.7958059\n",
      "The best auc in round 44: 0.7958067\n",
      "The best auc in round 45: 0.7958074\n",
      "The best auc in round 46: 0.7958090\n",
      "The best auc in round 47: 0.7958111\n",
      "The best auc in round 48: 0.7958133\n",
      "The best auc in round 49: 0.7958139\n",
      "The best auc in round 50: 0.7958149\n",
      "The best auc in round 51: 0.7958158\n",
      "The best auc in round 52: 0.7958165\n",
      "The best auc in round 53: 0.7958170\n",
      "The best auc in round 54: 0.7958176\n",
      "The best auc in round 55: 0.7958179\n",
      "The best auc in round 56: 0.7958184\n",
      "The best auc in round 57: 0.7958190\n",
      "The best auc in round 58: 0.7958190\n",
      "The best auc in round 59: 0.7958193\n",
      "The best auc in round 60: 0.7958196\n",
      "The best auc in round 61: 0.7958195\n",
      "The best auc in round 62: 0.7958203\n",
      "The best auc in round 63: 0.7958209\n",
      "The best auc in round 64: 0.7958210\n",
      "The best auc in round 65: 0.7958160\n",
      "The best auc in round 66: 0.7958035\n",
      "The best auc in round 67: 0.7958055\n",
      "The best auc in round 68: 0.7958073\n",
      "The best auc in round 69: 0.7958084\n",
      "The best auc in round 70: 0.7958096\n",
      "The best auc in round 71: 0.7958111\n",
      "The best auc in round 72: 0.7958121\n",
      "The best auc in round 73: 0.7958136\n",
      "The best auc in round 74: 0.7958152\n",
      "The best auc in round 75: 0.7958159\n",
      "The best auc in round 76: 0.7958174\n",
      "The best auc in round 77: 0.7958179\n",
      "The best auc in round 78: 0.7958192\n",
      "The best auc in round 79: 0.7958197\n",
      "The best auc in round 80: 0.7958203\n",
      "The best auc in round 81: 0.7958210\n",
      "The best auc in round 82: 0.7958218\n",
      "The best auc in round 83: 0.7958219\n",
      "The best auc in round 84: 0.7958225\n",
      "The best auc in round 85: 0.7958228\n",
      "The best auc in round 86: 0.7958231\n",
      "The best auc in round 87: 0.7958238\n",
      "The best auc in round 88: 0.7958244\n",
      "The best auc in round 89: 0.7958244\n",
      "The best auc in round 90: 0.7958244\n",
      "The best auc in round 91: 0.7958247\n",
      "The best auc in round 92: 0.7958255\n",
      "The best auc in round 93: 0.7958260\n",
      "The best auc in round 94: 0.7958261\n",
      "The best auc in round 95: 0.7958263\n",
      "The best auc in round 96: 0.7958264\n",
      "The best auc in round 97: 0.7958271\n",
      "The best auc in round 98: 0.7958274\n",
      "The best auc in round 99: 0.7958274\n",
      "The best auc in round 100: 0.7958275\n",
      "The best auc in round 101: 0.7958276\n",
      "The best auc in round 102: 0.7958279\n",
      "The best auc in round 103: 0.7958282\n",
      "The best auc in round 104: 0.7958281\n",
      "The best auc in round 105: 0.7958281\n",
      "The best auc in round 106: 0.7958282\n",
      "The best auc in round 107: 0.7958288\n",
      "The best auc in round 108: 0.7958287\n",
      "The best auc in round 109: 0.7958289\n",
      "The best auc in round 110: 0.7958286\n",
      "The best auc in round 111: 0.7958288\n",
      "The best auc in round 112: 0.7958289\n",
      "The best auc in round 113: 0.7958290\n",
      "The best auc in round 114: 0.7958292\n",
      "The best auc in round 115: 0.7958293\n",
      "The best auc in round 116: 0.7958295\n",
      "The best auc in round 117: 0.7958294\n",
      "The best auc in round 118: 0.7958295\n",
      "The best auc in round 119: 0.7958296\n",
      "The best auc in round 120: 0.7958293\n",
      "The best auc in round 121: 0.7958296\n",
      "The best auc in round 122: 0.7958295\n",
      "The best auc in round 123: 0.7958284\n",
      "The best auc in round 124: 0.7958285\n",
      "The best auc in round 125: 0.7958284\n",
      "The best auc in round 126: 0.7958287\n",
      "The best auc in round 127: 0.7958286\n",
      "The best auc in round 128: 0.7958285\n",
      "The best auc in round 129: 0.7958287\n",
      "The best auc in round 130: 0.7958287\n",
      "The best auc in round 131: 0.7958290\n",
      "The best auc in round 132: 0.7958289\n",
      "The best auc in round 133: 0.7958293\n",
      "The best auc in round 134: 0.7958294\n",
      "The best auc in round 135: 0.7958296\n",
      "The best auc in round 136: 0.7958293\n",
      "The best auc in round 137: 0.7958292\n",
      "The best auc in round 138: 0.7958295\n",
      "The best auc in round 139: 0.7958293\n",
      "The best auc in round 140: 0.7958295\n",
      "The best auc in round 141: 0.7958291\n",
      "The best auc in round 142: 0.7958293\n",
      "The best auc in round 143: 0.7958293\n",
      "The best auc in round 144: 0.7958295\n",
      "The best auc in round 145: 0.7958295\n",
      "The best auc in round 146: 0.7958293\n",
      "The best auc in round 147: 0.7958292\n",
      "The best auc in round 148: 0.7958293\n",
      "The best auc in round 149: 0.7958295\n",
      "The best auc in round 150: 0.7958293\n",
      "The best auc in round 151: 0.7958295\n",
      "The best auc in round 152: 0.7958295\n",
      "The best auc in round 153: 0.7958296\n",
      "The best auc in round 154: 0.7958296\n",
      "The best auc in round 155: 0.7958295\n",
      "The best auc in round 156: 0.7958297\n",
      "The best auc in round 157: 0.7958296\n",
      "The best auc in round 158: 0.7958289\n",
      "The best auc in round 159: 0.7958267\n",
      "The best auc in round 160: 0.7958270\n",
      "The best auc in round 161: 0.7958271\n",
      "The best auc in round 162: 0.7958272\n",
      "The best auc in round 163: 0.7958276\n",
      "The best auc in round 164: 0.7958276\n",
      "The best auc in round 165: 0.7958279\n",
      "The best auc in round 166: 0.7958280\n",
      "The best auc in round 167: 0.7958281\n",
      "The best auc in round 168: 0.7958282\n",
      "The best auc in round 169: 0.7958284\n",
      "The best auc in round 170: 0.7958285\n",
      "The best auc in round 171: 0.7958283\n",
      "The best auc in round 172: 0.7958283\n",
      "The best auc in round 173: 0.7958285\n",
      "The best auc in round 174: 0.7958287\n",
      "The best auc in round 175: 0.7958288\n",
      "The best auc in round 176: 0.7958289\n",
      "The best auc in round 177: 0.7958290\n",
      "The best auc in round 178: 0.7958293\n",
      "The best auc in round 179: 0.7958295\n",
      "The best auc in round 180: 0.7958296\n",
      "The best auc in round 181: 0.7958296\n",
      "The best auc in round 182: 0.7958296\n",
      "The best auc in round 183: 0.7958298\n",
      "The best auc in round 184: 0.7958300\n",
      "The best auc in round 185: 0.7958300\n",
      "The best auc in round 186: 0.7958303\n",
      "The best auc in round 187: 0.7958304\n",
      "The best auc in round 188: 0.7958304\n",
      "The best auc in round 189: 0.7958304\n",
      "The best auc in round 190: 0.7958303\n",
      "The best auc in round 191: 0.7958306\n",
      "The best auc in round 192: 0.7958308\n",
      "The best auc in round 193: 0.7958309\n",
      "The best auc in round 194: 0.7958308\n",
      "The best auc in round 195: 0.7958308\n",
      "The best auc in round 196: 0.7958306\n",
      "The best auc in round 197: 0.7958308\n",
      "The best auc in round 198: 0.7958308\n",
      "The best auc in round 199: 0.7958309\n",
      "The best auc in round 200: 0.7958310\n",
      "The best auc in round 201: 0.7958309\n",
      "The best auc in round 202: 0.7958309\n",
      "The best auc in round 203: 0.7958310\n",
      "The best auc in round 204: 0.7958307\n",
      "The best auc in round 205: 0.7958306\n",
      "The best auc in round 206: 0.7958306\n",
      "The best auc in round 207: 0.7958306\n",
      "The best auc in round 208: 0.7958308\n",
      "The best auc in round 209: 0.7958309\n",
      "The best auc in round 210: 0.7958309\n",
      "The best auc in round 211: 0.7958306\n",
      "The best auc in round 212: 0.7958306\n",
      "The best auc in round 213: 0.7958308\n",
      "The best auc in round 214: 0.7958308\n",
      "The best auc in round 215: 0.7958308\n",
      "The best auc in round 216: 0.7958307\n",
      "The best auc in round 217: 0.7958305\n",
      "The best auc in round 218: 0.7958307\n",
      "The best auc in round 219: 0.7958307\n",
      "The best auc in round 220: 0.7958308\n",
      "The best auc in round 221: 0.7958309\n",
      "The best auc in round 222: 0.7958309\n",
      "The best auc in round 223: 0.7958305\n",
      "The best auc in round 224: 0.7958299\n",
      "The best auc in round 225: 0.7958289\n",
      "The best auc in round 226: 0.7958274\n",
      "The best auc in round 227: 0.7958279\n",
      "The best auc in round 228: 0.7958277\n",
      "The best auc in round 229: 0.7958277\n",
      "The best auc in round 230: 0.7958279\n",
      "The best auc in round 231: 0.7958281\n",
      "The best auc in round 232: 0.7958284\n",
      "The best auc in round 233: 0.7958284\n",
      "The best auc in round 234: 0.7958286\n",
      "The best auc in round 235: 0.7958283\n",
      "The best auc in round 236: 0.7958287\n",
      "The best auc in round 237: 0.7958288\n",
      "The best auc in round 238: 0.7958288\n",
      "The best auc in round 239: 0.7958289\n",
      "The best auc in round 240: 0.7958288\n",
      "The best auc in round 241: 0.7958289\n",
      "The best auc in round 242: 0.7958289\n",
      "The best auc in round 243: 0.7958292\n",
      "The best auc in round 244: 0.7958291\n",
      "The best auc in round 245: 0.7958290\n",
      "The best auc in round 246: 0.7958290\n",
      "The best auc in round 247: 0.7958291\n",
      "The best auc in round 248: 0.7958292\n",
      "The best auc in round 249: 0.7958292\n",
      "The best auc in round 250: 0.7958294\n",
      "The best auc in round 251: 0.7958295\n",
      "The best auc in round 252: 0.7958293\n",
      "The best auc in round 253: 0.7958292\n",
      "The best auc in round 254: 0.7958294\n",
      "The best auc in round 255: 0.7958294\n",
      "The best auc in round 256: 0.7958291\n",
      "The best auc in round 257: 0.7958294\n",
      "The best auc in round 258: 0.7958294\n",
      "The best auc in round 259: 0.7958295\n",
      "The best auc in round 260: 0.7958295\n",
      "The best auc in round 261: 0.7958299\n",
      "The best auc in round 262: 0.7958297\n",
      "The best auc in round 263: 0.7958298\n",
      "The best auc in round 264: 0.7958299\n",
      "The best auc in round 265: 0.7958301\n",
      "The best auc in round 266: 0.7958300\n",
      "The best auc in round 267: 0.7958298\n",
      "The best auc in round 268: 0.7958302\n",
      "The best auc in round 269: 0.7958301\n",
      "The best auc in round 270: 0.7958302\n",
      "The best auc in round 271: 0.7958300\n",
      "The best auc in round 272: 0.7958301\n",
      "The best auc in round 273: 0.7958301\n",
      "The best auc in round 274: 0.7958302\n",
      "The best auc in round 275: 0.7958303\n",
      "The best auc in round 276: 0.7958304\n",
      "The best auc in round 277: 0.7958303\n",
      "The best auc in round 278: 0.7958302\n",
      "The best auc in round 279: 0.7958303\n",
      "The best auc in round 280: 0.7958305\n",
      "The best auc in round 281: 0.7958305\n",
      "The best auc in round 282: 0.7958306\n",
      "The best auc in round 283: 0.7958308\n",
      "The best auc in round 284: 0.7958306\n",
      "The best auc in round 285: 0.7958304\n",
      "The best auc in round 286: 0.7958303\n",
      "The best auc in round 287: 0.7958297\n",
      "The best auc in round 288: 0.7958288\n",
      "The best auc in round 289: 0.7958290\n",
      "The best auc in round 290: 0.7958291\n",
      "The best auc in round 291: 0.7958290\n",
      "The best auc in round 292: 0.7958290\n",
      "The best auc in round 293: 0.7958293\n",
      "The best auc in round 294: 0.7958292\n",
      "The best auc in round 295: 0.7958292\n",
      "The best auc in round 296: 0.7958294\n",
      "The best auc in round 297: 0.7958297\n",
      "The best auc in round 298: 0.7958298\n",
      "The best auc in round 299: 0.7958297\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZoAAAEKCAYAAAArYJMgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x384553c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_time=time.clock()\n",
    "\n",
    "y_greedybag, bag_count, true_best, count_best,hist_auc = greedy_bagging(preds_train, preds_test, y, nth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Model Stacking\n",
      "Total running time is 1753 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_time=time.clock()-start_time\n",
    "print('Completed Model Stacking')\n",
    "print('Total running time is %d seconds\\n' %total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   1.    0.    0.    0.    0.    4.    4.    0.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    3.   39.\n",
      "   62.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    6.\n",
      "    0.   26.  105.   49.]\n",
      "The best auc is 0.7958310 with bag_count\n",
      "[  1.   0.   0.   0.   0.   3.   2.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   1.  26.  43.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   1.   4.   0.  16.  71.  35.]\n"
     ]
    }
   ],
   "source": [
    "print(bag_count)\n",
    "print('The best auc is %9.7f with bag_count'%true_best)\n",
    "print(count_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203.0\n"
     ]
    }
   ],
   "source": [
    "num_models=np.array(count_best).sum()\n",
    "print(num_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model-1: sgd_0p771702_wl_ appears:\n",
      "       1 times in final 203 ensembles\n",
      "\n",
      "Model-2: sgd_0p770356_wl_ appears:\n",
      "       0 times in final 203 ensembles\n",
      "\n",
      "Model-3: sgd_0p769531_wl_ appears:\n",
      "       0 times in final 203 ensembles\n",
      "\n",
      "Model-4: svm-0p752773_wl_ appears:\n",
      "       0 times in final 203 ensembles\n",
      "\n",
      "Model-5: rf-335_ appears:\n",
      "       0 times in final 203 ensembles\n",
      "\n",
      "Model-6: rf-all_ appears:\n",
      "       3 times in final 203 ensembles\n",
      "\n",
      "Model-7: xgb-665_ appears:\n",
      "       2 times in final 203 ensembles\n",
      "\n",
      "Model-8: xgb-933_ appears:\n",
      "       0 times in final 203 ensembles\n",
      "\n",
      "Model-9: xgb-all_ appears:\n",
      "       0 times in final 203 ensembles\n",
      "\n",
      "Model-10: xgb_0p770751_wl_ appears:\n",
      "       0 times in final 203 ensembles\n",
      "\n",
      "Model-11: xgb_lr_0p777824_wl_ appears:\n",
      "       0 times in final 203 ensembles\n",
      "\n",
      "Model-12: xgb_lr_0p777125_50Segments_wl_ appears:\n",
      "       0 times in final 203 ensembles\n",
      "\n",
      "Model-13: xgb_lr_0p776415_wl_ appears:\n",
      "       0 times in final 203 ensembles\n",
      "\n",
      "Model-14: xgb_0p784886_wl_ appears:\n",
      "       0 times in final 203 ensembles\n",
      "\n",
      "Model-15: xgb_0p785604_wl_ appears:\n",
      "       0 times in final 203 ensembles\n",
      "\n",
      "Model-16: xgb_0p785120_wl_ appears:\n",
      "       0 times in final 203 ensembles\n",
      "\n",
      "Model-17: xgb_0p784916_wl_ appears:\n",
      "       0 times in final 203 ensembles\n",
      "\n",
      "Model-18: xgb_0p785155_wl_ appears:\n",
      "       0 times in final 203 ensembles\n",
      "\n",
      "Model-19: xgb_0p785468_wl_ appears:\n",
      "       0 times in final 203 ensembles\n",
      "\n",
      "Model-20: xgb_0p785787_wl_ appears:\n",
      "       0 times in final 203 ensembles\n",
      "\n",
      "Model-21: xgb_0p785890_wl_ appears:\n",
      "       0 times in final 203 ensembles\n",
      "\n",
      "Model-22: xgb_0p786040_wl_ appears:\n",
      "       0 times in final 203 ensembles\n",
      "\n",
      "Model-23: xgb_0p786290_wl_ appears:\n",
      "       1 times in final 203 ensembles\n",
      "\n",
      "Model-24: xgbmeta_0p793611_wl_ appears:\n",
      "       26 times in final 203 ensembles\n",
      "\n",
      "Model-25: xgbmeta_0p793971_wl_ appears:\n",
      "       43 times in final 203 ensembles\n",
      "\n",
      "Model-26: xgb_Oct192015134751_AUC_0p787695_sl_ appears:\n",
      "       0 times in final 203 ensembles\n",
      "\n",
      "Model-27: xgb_Oct192015065533_AUC_0p787632_sl_ appears:\n",
      "       0 times in final 203 ensembles\n",
      "\n",
      "Model-28: xgb_Oct192015133017_AUC_0p787608_sl_ appears:\n",
      "       0 times in final 203 ensembles\n",
      "\n",
      "Model-29: xgb_Oct192015101525_AUC_0p787437_sl_ appears:\n",
      "       0 times in final 203 ensembles\n",
      "\n",
      "Model-30: xgb_Oct192015120324_AUC_0p787252_sl_ appears:\n",
      "       0 times in final 203 ensembles\n",
      "\n",
      "Model-31: xgb_Oct192015085532_AUC_0p787197_sl_ appears:\n",
      "       0 times in final 203 ensembles\n",
      "\n",
      "Model-32: xgb_Oct192015040605_AUC_0p786733_sl_ appears:\n",
      "       0 times in final 203 ensembles\n",
      "\n",
      "Model-33: xgb_Oct192015051026_AUC_0p786338_sl_ appears:\n",
      "       0 times in final 203 ensembles\n",
      "\n",
      "Model-34: xgb_Oct192015120134_AUC_0p785606_sl_ appears:\n",
      "       0 times in final 203 ensembles\n",
      "\n",
      "Model-35: xgb_Oct192015052747_AUC_0p781263_sl_ appears:\n",
      "       1 times in final 203 ensembles\n",
      "\n",
      "Model-36: xgb_Oct192015065922_AUC_0p780004_sl_ appears:\n",
      "       4 times in final 203 ensembles\n",
      "\n",
      "Model-37: xgb_Oct192015154017_AUC_0p787790_sl_ appears:\n",
      "       0 times in final 203 ensembles\n",
      "\n",
      "Model-38: meta_xgb_Oct192015184228_AUC_0p794324_sl_ appears:\n",
      "       16 times in final 203 ensembles\n",
      "\n",
      "Model-39: meta_xgb_Oct192015184936_AUC_0p794619_sl_ appears:\n",
      "       71 times in final 203 ensembles\n",
      "\n",
      "Model-40: meta_xgb_Oct192015185918_AUC_0p794108_sl_ appears:\n",
      "       35 times in final 203 ensembles\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, model in enumerate(results):\n",
    "    print('Model-%d: %s appears:'%(i+1, model))\n",
    "    print('       %d times in final %d ensembles\\n'%(count_best[i], num_models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00492611  0.          0.          0.          0.          0.01477833\n",
      "  0.00985222  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.00492611  0.12807882  0.21182266  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.00492611  0.01970443  0.          0.07881773  0.34975369  0.17241379]\n"
     ]
    }
   ],
   "source": [
    "count_best = np.array(count_best)\n",
    "coef=count_best/float(count_best.sum())\n",
    "print(coef)\n",
    "\n",
    "yfinal = np.dot(preds_test, coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.39336944,  0.35207557,  0.27332168,  0.2771306 ,  0.48668372])"
      ]
     },
     "execution_count": 617,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yfinal[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "str1=time.strftime(\"%b%d%Y_%H%M%S\", time.localtime())\n",
    "outfile_greedy = path_to_results + 'ypred_modelensembling_greedy_'+str1+'.csv'\n",
    "\n",
    "save_results(test_ID, yfinal, outfile_greedy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ME_BG = ModelEnsembler()\n",
    "#yme_BG = ME_BG.Bagging(preds_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Least-square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LS AUC: 0.7957723\n",
      "[ 0.          0.          0.00871227  0.          0.          0.02898999\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.12279714  0.25077386  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.03925452  0.34698394  0.20248828]\n"
     ]
    }
   ],
   "source": [
    "ME_LS = ModelEnsembler()\n",
    "ME_LS.fit_LS(preds_train, y)\n",
    "yme_LS = ME_LS.predict_proba(preds_test)\n",
    "\n",
    "print('LS AUC: %9.7f'%metrics.roc_auc_score(y, ME_LS.predict_proba(preds_train)))\n",
    "print(ME_LS.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 AUC regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ME_AUCRG = ModelEnsembler()\n",
    "#ME_AUCRG.fit_AUC(preds_train,y)\n",
    "#yme_AUC = ME_AUCRG.predict_proba(preds_test)\n",
    "\n",
    "#print(ME_AUCRG.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Model Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#start_time=time.clock()\n",
    "\n",
    "#ME_STACK = ModelEnsembler()\n",
    "#yme_STACK = ME_STACK.stackingEnsembler(preds_train, y, preds_test)\n",
    "\n",
    "#total_time=time.clock()-start_time\n",
    "#print('Completed Model Stacking')\n",
    "#print('Total running time is %d seconds\\n' %total_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#str1=time.strftime(\"%b%d%Y_%H%M%S\", time.localtime())\n",
    "#outfile_BG = path_to_results + 'ypred_modelensembling_bagging_'+str1+'.csv'\n",
    "#outfile_LS = path_to_results + 'ypred_modelensembling_leastsquare_'+str1+'.csv'\n",
    "#outfile_AUC = path_to_results + 'ypred_modelensembling_AUCoptimzer_'+str1+'.csv'\n",
    "#outfile_STACK = path_to_results + 'ypred_modelensembling_stacking_'+str1+'.csv'\n",
    "\n",
    "#save_results(test_ID, yme_BG, outfile_BG)\n",
    "#save_results(test_ID, yme_LS, outfile_LS)\n",
    "#save_results(test_ID, yme_AUC, outfile_AUC)\n",
    "#save_results(test_ID, yme_STACK, outfile_STACK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print('The shape of saved results:')\n",
    "#print(test_ID.shape,yme_BG.shape,yme_LS.shape,yme_AUC.shape,yme_STACK.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(yme_BG[:8])\n",
    "#print(yme_LS[:8])\n",
    "#print(yme_AUC[:8])\n",
    "#print(yme_STACK[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#count=0\n",
    "#for i in range(yme_STACK.shape[0]):\n",
    "#    if yme_STACK[i]<0:\n",
    "#        count+=1\n",
    "#print(count)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Two-stage model with derived features (use cv-predictions as meta-features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
